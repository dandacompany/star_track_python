{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 시계열 예측: 실습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 1 & 2: AEP 에너지 소비량 데이터 로드 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋 로드\n",
    "energy_url = 'https://storage.googleapis.com/mledu-datasets/pjm_hourly_est.csv'\n",
    "df_energy = pd.read_csv(energy_url)\n",
    "\n",
    "print(\"--- AEP 에너지 소비량 데이터셋 (처음 5행) ---\")\n",
    "print(df_energy.head())\n",
    "\n",
    "# 2. 데이터 기본 정보 및 통계 요약 확인\n",
    "print(\"\\n--- 데이터프레임 정보 ---\")\n",
    "df_energy.info()\n",
    "\n",
    "print(\"\\n--- 통계 요약 ---\")\n",
    "print(df_energy.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 3 & 4: 시계열 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AEP 에너지 데이터셋 전처리\n",
    "df_energy['Datetime'] = pd.to_datetime(df_energy['Datetime'])\n",
    "df_energy.set_index('Datetime', inplace=True)\n",
    "\n",
    "# 2015-2016년 데이터 필터링\n",
    "df_energy_filtered = df_energy['2015-01-01':'2016-12-31'].copy()\n",
    "\n",
    "fig_energy = px.line(df_energy_filtered, y='AEP_MW', title='AEP Energy Consumption (2015-2016)')\n",
    "fig_energy.show()\n",
    "\n",
    "# 4. (가상) 서울시 대기오염 데이터 전처리\n",
    "apple_url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/09_Time_Series/Apple_Stock/appl_1980_2014.csv'\n",
    "df_air_mock = pd.read_csv(apple_url)\n",
    "df_air_mock['Date'] = pd.to_datetime(df_air_mock['Date'])\n",
    "df_air_mock.set_index('Date', inplace=True)\n",
    "df_air_mock_filtered = df_air_mock['2010':].copy()\n",
    "\n",
    "fig_air = px.line(df_air_mock_filtered, y='Adj. Close', title='(Mock) Air Pollution Index since 2010')\n",
    "fig_air.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 5: 특성 공학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. AEP 에너지 데이터셋 특성 공학\n",
    "df_energy_eng = df_energy_filtered.copy()\n",
    "\n",
    "day_of_week = df_energy_eng.index.dayofweek\n",
    "day_of_year = df_energy_eng.index.dayofyear\n",
    "\n",
    "df_energy_eng['DayOfWeek_sin'] = np.sin(day_of_week * (2 * np.pi / 7))\n",
    "df_energy_eng['DayOfWeek_cos'] = np.cos(day_of_week * (2 * np.pi / 7))\n",
    "df_energy_eng['DayOfYear_sin'] = np.sin(day_of_year * (2 * np.pi / 365.25))\n",
    "df_energy_eng['DayOfYear_cos'] = np.cos(day_of_year * (2 * np.pi / 365.25))\n",
    "\n",
    "print(\"특성 공학 후 데이터 샘플:\")\n",
    "print(df_energy_eng.head())\n",
    "\n",
    "fig_dayofweek = px.line(df_energy_eng.iloc[:168], y=['DayOfWeek_sin', 'DayOfWeek_cos'], title='Weekly Cycle') # 168 hours = 7 days\n",
    "fig_dayofweek.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 6 & 7: 데이터 분할 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 데이터 분할\n",
    "n_energy = len(df_energy_eng)\n",
    "train_energy_df = df_energy_eng[0:int(n_energy*0.8)]\n",
    "val_energy_df = df_energy_eng[int(n_energy*0.8):int(n_energy*0.9)]\n",
    "test_energy_df = df_energy_eng[int(n_energy*0.9):]\n",
    "\n",
    "# 7. 정규화\n",
    "train_energy_mean = train_energy_df.mean()\n",
    "train_energy_std = train_energy_df.std()\n",
    "\n",
    "train_energy_df = (train_energy_df - train_energy_mean) / train_energy_std\n",
    "val_energy_df = (val_energy_df - train_energy_mean) / train_energy_std\n",
    "test_energy_df = (test_energy_df - train_energy_mean) / train_energy_std\n",
    "\n",
    "print(\"정규화된 훈련 데이터 샘플:\")\n",
    "print(train_energy_df.head())\n",
    "\n",
    "# 8. 정규화된 데이터 분포 시각화\n",
    "fig_hist = px.histogram(train_energy_df, x='AEP_MW', nbins=50, title='Normalized Energy Consumption Distribution')\n",
    "fig_hist.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 8 & 9: 윈도우 생성\n",
    "*(WindowGenerator 클래스 코드는 튜토리얼 본문에 있으므로 여기서는 생략하고 바로 사용합니다.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WindowGenerator 클래스 정의 (튜토리얼에서 복사)\n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift, train_df, val_df, test_df, label_columns=None):\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'\n",
    "        ])\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,\n",
    "        )\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "# 8. 다중 스텝 예측 윈도우 생성\n",
    "multi_step_energy_window = WindowGenerator(\n",
    "    input_width=7*24, label_width=24, shift=24,\n",
    "    train_df=train_energy_df, val_df=val_energy_df, test_df=test_energy_df,\n",
    "    label_columns=['AEP_MW'])\n",
    "\n",
    "print(\"--- 다중 스텝 에너지 예측 윈도우 ---\")\n",
    "print(multi_step_energy_window)\n",
    "\n",
    "# 9. 단일 스텝 예측 윈도우 생성\n",
    "single_step_energy_window = WindowGenerator(\n",
    "    input_width=24, label_width=1, shift=1,\n",
    "    train_df=train_energy_df, val_df=val_energy_df, test_df=test_energy_df,\n",
    "    label_columns=['AEP_MW'])\n",
    "\n",
    "print(\"\\n--- 단일 스텝 에너지 예측 윈도우 ---\")\n",
    "print(single_step_energy_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 10: Dense 모델로 단일 스텝 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Dense 모델 구성\n",
    "dense_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(), # (batch, time, features) -> (batch, time * features)\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "dense_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "history = dense_model.fit(single_step_energy_window.train, epochs=10,\n",
    "                          validation_data=single_step_energy_window.val)\n",
    "\n",
    "test_performance_dense = dense_model.evaluate(single_step_energy_window.test)\n",
    "print(f\"\\nDense Model - Test MAE: {test_performance_dense[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 문제 11: LSTM 모델로 다중 스텝 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. LSTM 모델 구성\n",
    "OUT_STEPS = 24 # 24시간 예측\n",
    "num_features = train_energy_df.shape[1]\n",
    "\n",
    "lstm_energy_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(OUT_STEPS*1),\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, 1])\n",
    "])\n",
    "\n",
    "lstm_energy_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "history = lstm_energy_model.fit(multi_step_energy_window.train, epochs=10,\n",
    "                              validation_data=multi_step_energy_window.val)\n",
    "\n",
    "test_performance_lstm = lstm_energy_model.evaluate(multi_step_energy_window.test)\n",
    "print(f\"\\nLSTM Model - Test MAE: {test_performance_lstm[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
