{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj4HaIIuHAuj"
      },
      "source": [
        "# 🐍 파이썬 텍스트 분석: Chapter 6. Kiwipiepy와 최신 AI를 활용한 감성 분석\n",
        "\n",
        "이 노트북에서는 미리 정답(레이블)이 정해진 데이터를 사용하여 모델을 학습시키는 **지도 학습(Supervised Learning)**을 텍스트 분석에 적용하는 심화 방법을 배웁니다.\n",
        "\n",
        "특히, 기존의 형태소 분석기에서 더 빠르고 발전된 **Kiwipiepy**를 사용하여 텍스트를 전처리하고, 두 가지 다른 접근 방식으로 감성 분석 모델을 구축합니다.\n",
        "\n",
        "1.  **전통적인 머신러닝 방식**: `Kiwipiepy`로 전처리한 텍스트를 `TF-IDF`라는 기법으로 벡터화하여, 로지스틱 회귀 모델을 학습시킵니다.\n",
        "2.  **최신 AI 임베딩 방식**: `OpenAI`의 강력한 언어 모델을 사용하여 텍스트를 의미가 풍부한 벡터(임베딩)로 변환하고, 이를 기반으로 모델을 학습시켜 성능을 비교합니다.\n",
        "\n",
        "이 과정을 통해 수만 개의 영화 리뷰 텍스트를 이용해 해당 리뷰가 '긍정'적인지 '부정'적인지를 예측하는 감성 분석 모델을 직접 만들어보겠습니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 시작 전 준비: 라이브러리 설치 및 데이터 로드\n",
        "\n",
        "이번 실습에서는 먼저 `kiwipiepy`와 `openai` 라이브러리를 설치해야 합니다. `kiwipiepy`는 한국어 텍스트를 효과적으로 처리하기 위한 형태소 분석기이며, `openai`는 텍스트 임베딩을 위해 사용됩니다.\n",
        "\n",
        "데이터셋은 이전과 동일하게 대표적인 한국어 감성 분석 데이터셋인 **NSMC(Naver Sentiment Movie Corpus)** 를 사용합니다. 이 데이터셋은 네이버 영화의 리뷰 20만 개와 각 리뷰에 대한 긍정(레이블 1) 또는 부정(레이블 0) 평가를 포함하고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW44g6wIHAuk"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리 설치\n",
        "!pip install kiwipiepy pandas scikit-learn plotly openai tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from kiwipiepy import Kiwi\n",
        "import openai\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# tqdm을 pandas에 적용하기 위한 설정\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 데이터 다운로드 및 로드\n",
        "# 도커/로컬 환경에 따라 경로는 수정하셔야 합니다.\n",
        "train_df = pd.read_csv(\"../datasets/text/nsmc/ratings_train.txt\", sep='\\t')\n",
        "test_df = pd.read_csv(\"../datasets/text/nsmc/ratings_test.txt\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 데이터 정제 (결측치 및 중복 제거)\n",
        "train_df = train_df.dropna().drop_duplicates(subset=['document'])\n",
        "test_df = test_df.dropna().drop_duplicates(subset=['document'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 실습을 위해 데이터 샘플링\n",
        "train_df = train_df.sample(n=1000, random_state=42)\n",
        "test_df = test_df.sample(n=250, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Kiwipiepy를 사용한 텍스트 전처리 함수\n",
        "kiwi = Kiwi()\n",
        "# 파생 명사, 파생 부사 등을 더 잘게 분리하는 옵션 추가\n",
        "# 예: '고마움' -> '고맙/VA-I', '음/ETN'\n",
        "def kiwi_preprocess(text):\n",
        "    text = re.sub(r'[^가-힣\\s]', '', str(text)) # 한글과 공백만 남기기\n",
        "    tokens = kiwi.tokenize(text, split_complex=True)\n",
        "    # CountVectorizer/TfidfVectorizer 입력을 위해 공백으로 구분된 문자열 반환\n",
        "    return ' '.join([token.form for token in tokens])\n",
        "\n",
        "# 전처리 적용 (Kiwipiepy는 C++로 구현되어 있어 속도가 빠릅니다)\n",
        "train_df['document_processed'] = train_df['document'].progress_apply(kiwi_preprocess)\n",
        "test_df['document_processed'] = test_df['document'].progress_apply(kiwi_preprocess)\n",
        "\n",
        "print(\"데이터 준비 완료!\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOSskGI7HAul"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 1. TF-IDF를 이용한 전통적 감성 분석\n",
        "\n",
        "### 1. 특징 벡터화와 데이터 분리 (Feature Vectorization & Data Splitting)\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "모델 학습을 위해서는 텍스트 데이터를 숫자 벡터로 변환해야 합니다. 첫 번째 접근법으로, 단어의 빈도와 문서에서의 중요도를 함께 고려하는 **TF-IDF 방식**을 사용하겠습니다.\n",
        "\n",
        "또한, 모델의 성능을 객관적으로 평가하기 위해 전체 데이터를 **학습 데이터(Training Data)**와 **테스트 데이터(Test Data)**로 분리해야 합니다. 모델은 학습 데이터를 보고 패턴을 익히며, 이전에 한 번도 본 적 없는 테스트 데이터를 얼마나 잘 맞추는지를 통해 성능을 평가받게 됩니다. 이는 모델이 단순히 데이터를 암기하는 것(과적합, Overfitting)이 아니라, 일반화된 예측 능력을 갖췄는지 확인하기 위함입니다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQh7UUVJHAul"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋을 특징(X)과 레이블(y)로 분리\n",
        "X_train = train_df['document_processed']\n",
        "y_train = train_df['label']\n",
        "X_test = test_df['document_processed']\n",
        "y_test = test_df['label']\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "# 학습 데이터에 대해서는 fit과 transform을 모두 수행 (fit_transform)\n",
        "# 테스트 데이터에 대해서는 학습된 어휘사전을 기준으로 transform만 수행\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=3, ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF 벡터화 완료.\")\n",
        "print(f\"학습 데이터 (TF-IDF) 형태: {X_train_tfidf.shape}\")\n",
        "print(f\"테스트 데이터 (TF-IDF) 형태: {X_test_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH34PB6OHAul"
      },
      "source": [
        "#### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  `TfidfVectorizer`를 생성할 때, `max_features=2000` 파라미터를 추가하여 가장 빈도가 높은 2000개의 단어(n-gram 포함)만 사용하도록 설정해 보세요. TF-IDF 행렬의 형태(`shape`)가 어떻게 변하는지 확인해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.  `kiwipiepy`의 `tokenize` 메소드에는 `split_complex` 외에도 `normalize_coda=True`와 같은 유용한 옵션이 있습니다. 이 옵션은 '먹었엌ㅋㅋ'와 같이 어미 뒤에 자음이 붙는 신조어를 '먹었어'와 'ㅋㅋㅋ'로 분리해줍니다. `kiwi_preprocess` 함수에 이 옵션을 추가하고 전처리를 다시 실행한 뒤, TF-IDF 행렬의 크기가 어떻게 변하는지 관찰해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "### 2. 머신러닝 모델 학습 및 예측 (Model Training & Prediction)\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "이제 준비된 숫자 데이터(TF-IDF 벡터)를 머신러닝 모델에 입력하여 학습시킬 차례입니다. 텍스트 분류 문제에서 준수한 성능을 보이는 **로지스틱 회귀(Logistic Regression)** 모델을 사용하겠습니다. `fit` 메소드를 사용하여 모델은 TF-IDF 벡터(특징)와 감성 레이블(정답) 사이의 관계를 학습합니다. 학습이 완료된 후에는 `predict` 메소드를 사용하여 새로운 데이터의 정답을 예측할 수 있습니다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgooItA8HAul"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. 로지스틱 회귀 모델 생성 및 학습\n",
        "lr_model = LogisticRegression(random_state=42, C=5, max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "print(\"로지스틱 회귀 모델 학습 완료 (TF-IDF 기반).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 테스트 데이터에 대한 예측 수행\n",
        "y_pred = lr_model.predict(X_test_tfidf)\n",
        "print(\"테스트 데이터 예측 완료.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 결과 일부 확인\n",
        "print(\"실제 값 (처음 10개):\", list(y_test[:10]))\n",
        "print(\"예측 값 (처음 10개):\", list(y_pred[:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp3JnEeJHAum"
      },
      "source": [
        "#### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  로지스틱 회귀 대신, 또 다른 텍스트 분류 모델인 **나이브 베이즈(Naive Bayes)** 모델(`sklearn.naive_bayes.MultinomialNB`)을 사용하여 동일한 데이터로 학습시키고 예측을 수행해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 작성\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = nb.predict(X_test_tfidf)\n",
        "\n",
        "print(\"실제 값 (처음 10개):\", list(y_test[:10]))\n",
        "print(\"예측 값 (처음 10개):\", list(y_pred[:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.  내가 직접 작성한 리뷰의 감성을 예측하는 함수 `predict_my_review_tfidf(text)`를 만들어보세요. 함수 내부는 아래 순서를 따라야 합니다.\n",
        "    * 텍스트 전처리 (`kiwi_preprocess` 함수 사용)\n",
        "    * 전처리된 텍스트를 TF-IDF 벡터로 변환 (`tfidf_vectorizer.transform` 사용)\n",
        "    * 학습된 `lr_model`로 예측 (`lr_model.predict` 사용)\n",
        "    * \"이 리뷰는 [긍정/부정]입니다.\" 라고 결과를 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 작성\n",
        "\n",
        "from kiwipiepy import Kiwi\n",
        "\n",
        "kiwi = Kiwi()\n",
        "\n",
        "\n",
        "def kiwi_preprocess(text) :\n",
        "    return \" \".join([tok.form for tok in kiwi.tokenize(text, skip_space=True)])\n",
        "\n",
        "def predict_my_review_tfidf(text) :\n",
        "    tokenized_text = kiwi_preprocess(text)\n",
        "    tfidf_matrix = tfidf_vectorizer.transform([tokenized_text])\n",
        "    label = lr_model.predict(tfidf_matrix)\n",
        "    if label == 0 :\n",
        "        return \"부정입니다.\"\n",
        "    else :\n",
        "        return \"긍정입니다.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "### 3. 모델 성능 평가하기 (Model Performance Evaluation)\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "모델이 예측을 얼마나 잘 수행했는지 정량적으로 평가하는 것은 매우 중요합니다. 이를 위해 다양한 **평가 지표**를 사용합니다.\n",
        "\n",
        "* **정확도 (Accuracy)**: 전체 예측 중 올바르게 예측한 비율. 가장 직관적이지만, 데이터의 클래스(긍정/부정)가 불균형할 경우 성능을 왜곡할 수 있습니다.\n",
        "* **정밀도 (Precision)**: 모델이 '긍정'으로 예측한 것들 중, 실제 '긍정'인 리뷰의 비율.\n",
        "* **재현율 (Recall)**: 실제 '긍정'인 리뷰들 중, 모델이 '긍정'으로 예측해낸 비율.\n",
        "* **F1 점수 (F1-Score)**: 정밀도와 재현율의 조화 평균. 두 지표가 모두 중요할 때 사용하는 균형 잡힌 지표입니다.\n",
        "* **혼동 행렬 (Confusion Matrix)**: 모델의 예측 결과를 표 형태로 정리한 것. True Positive, False Positive, True Negative, False Negative 값을 통해 모델이 어떤 부분에서 실수를 하는지 직관적으로 파악할 수 있습니다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "emo2y04PHAum"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "\n",
        "# 각 평가 지표 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 결과를 데이터프레임으로 저장 (나중에 비교 시각화를 위함)\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "    'TF-IDF': [accuracy, precision, recall, f1]\n",
        "})\n",
        "\n",
        "print(\"--- TF-IDF 기반 모델 성능 ---\")\n",
        "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "print(f\"F1 점수 (F1 Score): {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 혼동 행렬 시각화\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=conf_matrix,\n",
        "    x=['부정(예측)', '긍정(예측)'],\n",
        "    y=['부정(실제)', '긍정(실제)'],\n",
        "    colorscale='Blues'\n",
        ")\n",
        "fig.update_layout(title_text='<b>혼동 행렬 (Confusion Matrix) - TF-IDF</b>')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvR6eAcMHAum"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2. OpenAI 임베딩을 이용한 최신 AI 감성 분석\n",
        "\n",
        "### 4. OpenAI 임베딩으로 특징 벡터화하기\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "TF-IDF는 간단하고 효과적이지만, 단어의 '의미' 자체를 이해하지는 못합니다. 예를 들어, '재미있다'와 '흥미롭다'는 의미가 비슷하지만 TF-IDF는 이들을 완전히 다른 단어로 취급합니다.\n",
        "\n",
        "**텍스트 임베딩(Text Embedding)**은 이러한 한계를 극복하기 위한 기술입니다. 텍스트를 의미적 관계가 보존된 고차원의 **밀집 벡터(Dense Vector)**로 표현합니다. 이 벡터 공간에서는 의미가 비슷한 단어나 문장들이 서로 가까운 위치에 존재하게 됩니다.\n",
        "\n",
        "여기서는 `OpenAI`가 제공하는 사전 학습된(Pre-trained) 임베딩 모델(`text-embedding-3-small`)을 사용하여, 우리 데이터의 각 리뷰를 고유한 의미 벡터로 변환하겠습니다. 이렇게 얻은 벡터는 그 자체로 매우 강력한 특징(Feature)이 되어 머신러닝 모델의 성능을 크게 향상시킬 수 있습니다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UPSEkXyHAum"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "# 🚨 중요: OpenAI API 키 설정\n",
        "# 별도의 설정 파일(.env)을 사용하는 것이 안전합니다.\n",
        "# https://platform.openai.com/api-keys 에서 키를 발급받을 수 있습니다.\n",
        "# 본인의 OpenAI API 키를 입력하세요.\n",
        "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "# client = openai.OpenAI() # 환경변수 OPENAI_API_KEY에 키가 등록되어 있으면 자동으로 입력이 됩니다.\n",
        "client.models.list() # API 키 유효성 검사\n",
        "print(\"✅ OpenAI API 키가 성공적으로 설정되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트를 임베딩 벡터로 변환하는 함수\n",
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "    # OpenAI 정책에 따라 \\n 문자를 공백으로 치환\n",
        "    text = str(text).replace(\"\\n\", \" \")\n",
        "    if not text.strip(): # 비어있거나 공백만 있는 텍스트 처리\n",
        "        return None\n",
        "    try:\n",
        "        return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "    except Exception as e:\n",
        "        print(f\"임베딩 생성 중 오류 발생: {text[:30]}... - {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 학습 데이터와 테스트 데이터에 임베딩 적용\n",
        "# # 이 과정은 OpenAI API를 호출하므로 인터넷 연결이 필요하며, 데이터 양에 따라 시간이 소요될 수 있습니다.\n",
        "# print(\"학습 데이터 임베딩을 시작합니다...\")\n",
        "# train_df['embedding'] = train_df['document_processed'].progress_apply(get_embedding)\n",
        "# print(\"\\n테스트 데이터 임베딩을 시작합니다...\")\n",
        "# test_df['embedding'] = test_df['document_processed'].progress_apply(get_embedding)\n",
        "\n",
        "# # 임베딩 생성에 실패한 경우 (예: API 오류, 빈 텍스트) 해당 행 제거\n",
        "# train_df_emb = train_df.dropna(subset=['embedding'])\n",
        "# test_df_emb = test_df.dropna(subset=['embedding'])\n",
        "\n",
        "# print(f\"임베딩 생성 완료. {len(train_df) - len(train_df_emb)}개의 학습 데이터, {len(test_df) - len(test_df_emb)}개의 테스트 데이터가 제거되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 저장된 임베딩 데이터 로드\n",
        "import pickle\n",
        "\n",
        "with open('../datasets/text/nsmc/train_df.pkl', 'rb') as f:\n",
        "    train_df = pickle.load(f)\n",
        "\n",
        "with open('../datasets/text/nsmc/test_df.pkl', 'rb') as f:\n",
        "    test_df = pickle.load(f)\n",
        "\n",
        "# 임베딩이 없는 행 제거\n",
        "train_df_emb = train_df.dropna(subset=['embedding'])\n",
        "test_df_emb = test_df.dropna(subset=['embedding'])\n",
        "\n",
        "print(\"저장된 임베딩 데이터를 성공적으로 로드했습니다.\")\n",
        "print(f\"로드된 학습 데이터 크기: {len(train_df_emb)}개\")\n",
        "print(f\"로드된 테스트 데이터 크기: {len(test_df_emb)}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNDd-5qsHAum"
      },
      "source": [
        "---\n",
        "\n",
        "### 5. 임베딩 벡터로 모델 학습 및 평가하기\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "이제 각 리뷰는 1536차원(`text-embedding-3-small` 기준)의 숫자 벡터로 변환되었습니다. 이 임베딩 벡터를 특징(X)으로, 기존의 긍정/부정 레이블(y)을 정답으로 사용하여 새로운 로지스틱 회귀 모델을 학습시키겠습니다.\n",
        "\n",
        "과연 단어의 의미를 이해하는 임베딩 벡터가 TF-IDF보다 더 나은 성능을 보여줄까요? 동일한 평가 지표를 통해 두 모델의 성능을 직접 비교해봅시다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlBNvTFwHAum"
      },
      "outputs": [],
      "source": [
        "# 1. 임베딩 벡터와 레이블 분리\n",
        "X_train_emb = np.array(train_df_emb['embedding'].tolist())\n",
        "y_train_emb = train_df_emb['label']\n",
        "X_test_emb = np.array(test_df_emb['embedding'].tolist())\n",
        "y_test_emb = test_df_emb['label']\n",
        "\n",
        "print(f\"학습 데이터 (Embedding) 형태: {X_train_emb.shape}\")\n",
        "print(f\"테스트 데이터 (Embedding) 형태: {X_test_emb.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 새로운 로지스틱 회귀 모델 생성 및 학습\n",
        "lr_model_emb = LogisticRegression(random_state=42, C=5, max_iter=1000)\n",
        "lr_model_emb.fit(X_train_emb, y_train_emb)\n",
        "print(\"로지스틱 회귀 모델 학습 완료 (OpenAI Embedding 기반).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 테스트 데이터 예측 및 성능 평가\n",
        "y_pred_emb = lr_model_emb.predict(X_test_emb)\n",
        "\n",
        "accuracy_emb = accuracy_score(y_test_emb, y_pred_emb)\n",
        "precision_emb = precision_score(y_test_emb, y_pred_emb)\n",
        "recall_emb = recall_score(y_test_emb, y_pred_emb)\n",
        "f1_emb = f1_score(y_test_emb, y_pred_emb)\n",
        "\n",
        "# 평가 결과를 기존 데이터프레임에 추가\n",
        "metrics_df['OpenAI_Embedding'] = [accuracy_emb, precision_emb, recall_emb, f1_emb]\n",
        "\n",
        "print(\"--- OpenAI Embedding 기반 모델 성능 ---\")\n",
        "print(metrics_df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. 혼동 행렬 시각화\n",
        "conf_matrix_emb = confusion_matrix(y_test_emb, y_pred_emb)\n",
        "fig_emb = ff.create_annotated_heatmap(\n",
        "    z=conf_matrix_emb,\n",
        "    x=['부정(예측)', '긍정(예측)'],\n",
        "    y=['부정(실제)', '긍정(실제)'],\n",
        "    colorscale='Greens'\n",
        ")\n",
        "fig_emb.update_layout(title_text='<b>혼동 행렬 (Confusion Matrix) - OpenAI Embedding</b>')\n",
        "fig_emb.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. 두 모델 성능 비교 시각화\n",
        "fig_compare = px.bar(\n",
        "    metrics_df,\n",
        "    x='Metric',\n",
        "    y=['TF-IDF', 'OpenAI_Embedding'],\n",
        "    barmode='group',\n",
        "    title='<b>TF-IDF vs OpenAI Embedding 모델 성능 비교</b>',\n",
        "    labels={'value': 'Score', 'variable': 'Model'},\n",
        "    text_auto='.4f'\n",
        ")\n",
        "fig_compare.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl2ykujcHAun"
      },
      "source": [
        "#### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  OpenAI에는 `text-embedding-3-small` 외에 `text-embedding-3-large`와 같은 더 큰 모델이 있습니다. `get_embedding` 함수에서 모델 이름을 변경하여 임베딩을 생성하고, 성능이 어떻게 달라지는지 비교해보세요. (주의: 더 큰 모델은 비용과 시간이 더 많이 소요됩니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 200개의 데이터셋만 사용하세요. (학습목적에 맞게 시간과 비용을 줄이기 위함)\n",
        "train_200_df = train_df.sample(200)\n",
        "test_200_df = test_df.sample(200)\n",
        "train_200_df['large_embedding'] = train_200_df['document_processed'].progress_apply(lambda text: get_embedding(text, model=\"text-embedding-3-large\"))\n",
        "test_200_df['large_embedding'] = test_200_df['document_processed'].progress_apply(lambda text: get_embedding(text, model=\"text-embedding-3-large\"))\n",
        "\n",
        "train_200_df_emb = train_200_df.dropna(subset=['large_embedding'])\n",
        "test_200_df_emb = test_200_df.dropna(subset=['large_embedding'])\n",
        "\n",
        "print(f\"로드된 학습 데이터 크기: {len(train_200_df_emb)}개\")\n",
        "print(f\"로드된 테스트 데이터 크기: {len(test_200_df_emb)}개\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "large_emb_lr_model = LogisticRegression(random_state=42, C=5, max_iter=1000)\n",
        "\n",
        "large_emb_lr_model.fit(train_200_df_emb['large_embedding'].tolist(), train_200_df_emb['label'])\n",
        "\n",
        "y_pred_large_emb = large_emb_lr_model.predict(test_200_df_emb['large_embedding'].tolist())\n",
        "\n",
        "print(f\"Large Embedding 모델 정확도: {accuracy_score(test_200_df_emb['label'], y_pred_large_emb)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.  로지스틱 회귀 모델의 `C` 파라미터는 규제(Regularization)의 강도를 조절합니다. `C` 값을 1, 5, 10으로 변경해가며 임베딩 기반 모델을 다시 학습하고, 각 경우의 정확도가 어떻게 변하는지 확인해보세요. `C` 값이 클수록 규제가 약해집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 코드 작성\n",
        "custom_large_emb_lr_models = {\n",
        "    f\"C{c}\": LogisticRegression(random_state=42, C=c, max_iter=1000)\n",
        "    for c in [1,5,10]\n",
        "}\n",
        "\n",
        "for c, model in custom_large_emb_lr_models.items():\n",
        "    model.fit(train_200_df_emb['large_embedding'].tolist(), train_200_df_emb['label'])\n",
        "    y_pred_large_emb = model.predict(test_200_df_emb['large_embedding'].tolist())\n",
        "    print(f\"Large Embedding 모델({c}) 정확도: {accuracy_score(test_200_df_emb['label'], y_pred_large_emb)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3. 제로샷 분류: 레이블 임베딩 유사도 활용\n",
        "\n",
        "### 6. 레이블 의미 유사도를 이용한 제로샷(Zero-Shot) 감성 분석\n",
        "\n",
        "#### 💡 개념 (Concept)\n",
        "\n",
        "지금까지 우리는 (텍스트 벡터, 레이블) 쌍으로 구성된 학습 데이터를 사용하여 분류 모델(`LogisticRegression`)을 '학습'시켰습니다. 하지만 OpenAI와 같은 강력한 임베딩 모델을 사용하면, 모델을 전혀 학습시키지 않고도 분류를 수행하는 **제로샷(Zero-Shot) 분류**가 가능합니다.\n",
        "\n",
        "아이디어는 매우 직관적입니다.\n",
        "1.  분석할 문장 (예: \"배우들 연기가 정말 환상적이었어요.\")의 임베딩 벡터를 구합니다.\n",
        "2.  우리가 분류하고 싶은 레이블, 즉 **\"긍정\"이라는 단어와 \"부정\"이라는 단어 자체의 임베딩 벡터**를 구합니다.\n",
        "3.  분석할 문장의 벡터가 '긍정' 벡터와 '부정' 벡터 중 어느 쪽과 더 가까운지(유사한지)를 계산합니다.\n",
        "4.  더 가까운 쪽 레이블로 문장을 분류합니다.\n",
        "\n",
        "이 방식은 모델이 텍스트와 레이블의 '의미'를 벡터 공간에서 이해하고 있다는 전제 하에 작동합니다. 별도의 학습 데이터가 필요 없기 때문에 새로운 레이블(예: '중립')을 추가하는 데 매우 유연하다는 엄청난 장점이 있습니다.\n",
        "\n",
        "벡터 간의 유사도는 주로 **코사인 유사도(Cosine Similarity)**로 측정합니다. 두 벡터가 이루는 각도의 코사인 값으로, 방향이 완전히 같으면 1, 90°로 직교하면 0, 완전히 반대 방향이면 -1의 값을 가집니다.\n",
        "\n",
        "#### 💻 예시 코드 (Example Code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "\n",
        "# 코사인 유사도 계산 함수\n",
        "def cosine_similarity(A, B):\n",
        "    if A is None or B is None:\n",
        "        return -1 # 오류 또는 유효하지 않은 임베딩\n",
        "    return dot(A, B) / (norm(A) * norm(B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 분류할 레이블 정의 및 임베딩\n",
        "# \"긍정\", \"부정\" 보다 좀 더 풍부한 표현이 성능에 도움이 될 수 있습니다.\n",
        "positive_label_text = \"매우 긍정적이고 좋은 평가\"\n",
        "negative_label_text = \"매우 부정적이고 나쁜 평가\"\n",
        "\n",
        "positive_embedding = get_embedding(positive_label_text)\n",
        "negative_embedding = get_embedding(negative_label_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. 제로샷 예측 수행\n",
        "# 테스트셋의 각 리뷰 임베딩에 대해 레이블 임베딩과의 유사도 계산\n",
        "y_pred_zero_shot = []\n",
        "for review_embedding in tqdm(X_test_emb, desc=\"Zero-Shot 예측 중\"):\n",
        "    sim_positive = cosine_similarity(review_embedding, positive_embedding)\n",
        "    sim_negative = cosine_similarity(review_embedding, negative_embedding)\n",
        "\n",
        "    if sim_positive > sim_negative:\n",
        "        y_pred_zero_shot.append(1) # 긍정\n",
        "    else:\n",
        "        y_pred_zero_shot.append(0) # 부정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 제로샷 분류 성능 평가\n",
        "accuracy_zs = accuracy_score(y_test_emb, y_pred_zero_shot)\n",
        "precision_zs = precision_score(y_test_emb, y_pred_zero_shot)\n",
        "recall_zs = recall_score(y_test_emb, y_pred_zero_shot)\n",
        "f1_zs = f1_score(y_test_emb, y_pred_zero_shot)\n",
        "\n",
        "# 평가 결과를 데이터프레임에 추가\n",
        "metrics_df['OpenAI_Zero_Shot'] = [accuracy_zs, precision_zs, recall_zs, f1_zs]\n",
        "\n",
        "print(\"--- OpenAI Zero-Shot 기반 모델 성능 ---\")\n",
        "print(metrics_df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "positive_large_embedding = get_embedding(positive_label_text, model='text-embedding-3-large')\n",
        "negative_large_embedding = get_embedding(negative_label_text, model='text-embedding-3-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_large_model_zero_shot = []\n",
        "for review_embedding in tqdm(test_200_df_emb['large_embedding'].tolist(), desc=\"Zero-Shot 예측 중\"):\n",
        "    sim_positive = cosine_similarity(review_embedding, positive_large_embedding)\n",
        "    sim_negative = cosine_similarity(review_embedding, negative_large_embedding)\n",
        "\n",
        "    if sim_positive > sim_negative:\n",
        "        y_pred_large_model_zero_shot.append(1) # 긍정\n",
        "    else:\n",
        "        y_pred_large_model_zero_shot.append(0) # 부정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. 제로샷 분류 성능 평가\n",
        "accuracy_zs = accuracy_score(test_200_df_emb['label'].tolist(), y_pred_large_model_zero_shot)\n",
        "precision_zs = precision_score(test_200_df_emb['label'].tolist(), y_pred_large_model_zero_shot)\n",
        "recall_zs = recall_score(test_200_df_emb['label'].tolist(), y_pred_large_model_zero_shot)\n",
        "f1_zs = f1_score(test_200_df_emb['label'].tolist(), y_pred_large_model_zero_shot)\n",
        "\n",
        "# 평가 결과를 데이터프레임에 추가\n",
        "metrics_df['OpenAI_Large_Model_Zero_Shot'] = [accuracy_zs, precision_zs, recall_zs, f1_zs]\n",
        "\n",
        "print(\"--- OpenAI Zero-Shot 기반 모델 성능 ---\")\n",
        "print(metrics_df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. 혼동 행렬 시각화\n",
        "conf_matrix_zs = confusion_matrix(y_test_emb, y_pred_zero_shot)\n",
        "fig_zs = ff.create_annotated_heatmap(\n",
        "    z=conf_matrix_zs,\n",
        "    x=['부정(예측)', '긍정(예측)'],\n",
        "    y=['부정(실제)', '긍정(실제)'],\n",
        "    colorscale='Oranges'\n",
        ")\n",
        "fig_zs.update_layout(title_text='<b>혼동 행렬 (Confusion Matrix) - OpenAI Zero-Shot</b>')\n",
        "fig_zs.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. 세 가지 모델 성능 비교 시각화\n",
        "fig_compare_all = px.bar(\n",
        "    metrics_df,\n",
        "    x='Metric',\n",
        "    y=['TF-IDF', 'OpenAI_Embedding', 'OpenAI_Zero_Shot'],\n",
        "    barmode='group',\n",
        "    title='<b>세 가지 방식 모델 성능 비교</b>',\n",
        "    labels={'value': 'Score', 'variable': 'Model'},\n",
        "    text_auto='.4f'\n",
        ")\n",
        "fig_compare_all.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  레이블의 표현 방식은 제로샷 분류 성능에 영향을 미칠 수 있습니다. `positive_label_text`를 '아주 재미있고 훌륭한 영화'와 같이 더 구체적이고 감정이 풍부한 표현으로 바꿔보세요. 부정 레이블도 '지루하고 실망스러운 영화' 등으로 바꾸어 성능이 어떻게 변하는지 확인해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 새로운 레이블 정의\n",
        "positive_label_enhanced = \"아주 재미있고 훌륭한 영화\"\n",
        "negative_label_enhanced = \"지루하고 실망스러운 영화\"\n",
        "\n",
        "# 향상된 레이블의 임베딩 계산\n",
        "positive_embedding_enhanced = get_embedding(positive_label_enhanced)\n",
        "negative_embedding_enhanced = get_embedding(negative_label_enhanced)\n",
        "\n",
        "# 향상된 레이블로 제로샷 예측 수행\n",
        "y_pred_enhanced_zero_shot = []\n",
        "\n",
        "print(\"향상된 레이블로 Zero-Shot 예측 중...\")\n",
        "for embedding in tqdm(test_200_df_emb['embedding'].tolist(), desc=\"향상된 Zero-Shot 예측 중\"):\n",
        "    # 각 레이블과의 코사인 유사도 계산\n",
        "    pos_similarity = cosine_similarity(embedding, positive_embedding_enhanced)\n",
        "    neg_similarity = cosine_similarity(embedding, negative_embedding_enhanced)\n",
        "    \n",
        "    # 더 높은 유사도를 가진 레이블로 예측\n",
        "    if pos_similarity > neg_similarity:\n",
        "        y_pred_enhanced_zero_shot.append(1)  # 긍정\n",
        "    else:\n",
        "        y_pred_enhanced_zero_shot.append(0)  # 부정\n",
        "\n",
        "# 향상된 모델 성능 평가\n",
        "accuracy_enhanced = accuracy_score(test_200_df_emb['label'].tolist(), y_pred_enhanced_zero_shot)\n",
        "precision_enhanced = precision_score(test_200_df_emb['label'].tolist(), y_pred_enhanced_zero_shot)\n",
        "recall_enhanced = recall_score(test_200_df_emb['label'].tolist(), y_pred_enhanced_zero_shot)\n",
        "f1_enhanced = f1_score(test_200_df_emb['label'].tolist(), y_pred_enhanced_zero_shot)\n",
        "\n",
        "# 기존 결과와 비교\n",
        "print(\"--- 레이블 개선 전후 성능 비교 ---\")\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Original_Labels': [accuracy_zs, precision_zs, recall_zs, f1_zs],\n",
        "    'Enhanced_Labels': [accuracy_enhanced, precision_enhanced, recall_enhanced, f1_enhanced]\n",
        "})\n",
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 성능 개선 시각화\n",
        "fig_enhancement = px.bar(\n",
        "    comparison_df,\n",
        "    x='Metric',\n",
        "    y=['Original_Labels', 'Enhanced_Labels'],\n",
        "    barmode='group',\n",
        "    title='<b>레이블 개선 전후 Zero-Shot 성능 비교</b>',\n",
        "    labels={'value': 'Score', 'variable': 'Label Type'},\n",
        "    text_auto='.4f'\n",
        ")\n",
        "fig_enhancement.show()\n",
        "\n",
        "# 혼동 행렬 비교\n",
        "conf_matrix_enhanced = confusion_matrix(test_200_df_emb['label'].tolist(), y_pred_enhanced_zero_shot)\n",
        "fig_enhanced_cm = ff.create_annotated_heatmap(\n",
        "    z=conf_matrix_enhanced,\n",
        "    x=['부정(예측)', '긍정(예측)'],\n",
        "    y=['부정(실제)', '긍정(실제)'],\n",
        "    colorscale='Greens'\n",
        ")\n",
        "fig_enhanced_cm.update_layout(title_text='<b>혼동 행렬 - 향상된 레이블 Zero-Shot</b>')\n",
        "fig_enhanced_cm.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.  현재는 '긍정'/'부정'의 이진 분류만 수행했습니다. 이 제로샷 기법을 '코미디', '액션', '로맨스', '공포'와 같은 다중 장르 분류 문제에 적용하는 함수 `predict_genre_zero_shot(text)`를 만들어 보세요. 이 함수는 리뷰 텍스트를 입력받아, 4개의 장르 레이블과의 임베딩 유사도를 각각 계산하고 가장 유사도가 높은 장르를 반환해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 연습 문제 2: 다중 장르 분류를 위한 제로샷 함수 구현\n",
        "\n",
        "def predict_genre_zero_shot(text):\n",
        "    \"\"\"\n",
        "    영화 리뷰 텍스트를 입력받아 장르를 예측하는 제로샷 분류 함수\n",
        "    \n",
        "    Args:\n",
        "        text (str): 분류할 영화 리뷰 텍스트\n",
        "        \n",
        "    Returns:\n",
        "        str: 예측된 장르 ('코미디', '액션', '로맨스', '공포')\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        return \"오류: OpenAI 클라이언트가 설정되지 않았습니다.\"\n",
        "    \n",
        "    # 장르 레이블 정의\n",
        "    genre_labels = {\n",
        "        '코미디': '재미있고 유머러스한 코미디 영화',\n",
        "        '액션': '스릴 넘치고 박진감 있는 액션 영화', \n",
        "        '로맨스': '감동적이고 로맨틱한 사랑 영화',\n",
        "        '공포': '무섭고 긴장감 넘치는 공포 영화'\n",
        "    }\n",
        "    \n",
        "    # 입력 텍스트 전처리\n",
        "    processed_text = kiwi_preprocess(text)\n",
        "    \n",
        "    # 입력 텍스트의 임베딩 계산\n",
        "    text_embedding = get_embedding(processed_text)\n",
        "    if text_embedding is None:\n",
        "        return \"오류: 텍스트 임베딩 생성 실패\"\n",
        "    \n",
        "    # 각 장르 레이블과의 유사도 계산\n",
        "    similarities = {}\n",
        "    for genre, label_text in genre_labels.items():\n",
        "        label_embedding = get_embedding(label_text)\n",
        "        if label_embedding is not None:\n",
        "            similarity = cosine_similarity(text_embedding, label_embedding)\n",
        "            similarities[genre] = similarity\n",
        "    \n",
        "    # 가장 높은 유사도를 가진 장르 반환\n",
        "    if similarities:\n",
        "        predicted_genre = max(similarities, key=similarities.get)\n",
        "        return predicted_genre\n",
        "    else:\n",
        "        return \"오류: 장르 예측 실패\"\n",
        "\n",
        "# 함수 테스트\n",
        "test_reviews = [\n",
        "    \"정말 웃겨서 배꼽 빠질 뻔했어요. 개그맨들의 연기가 너무 재밌었습니다.\",\n",
        "    \"액션 장면이 정말 박진감 넘치고 스턴트가 대단했어요. 손에 땀을 쥐게 하는 영화입니다.\",\n",
        "    \"두 주인공의 사랑 이야기가 너무 감동적이었어요. 눈물이 날 정도로 아름다운 로맨스였습니다.\",\n",
        "    \"정말 무서워서 잠을 못 잘 것 같아요. 귀신이 나오는 장면에서 소리를 질렀습니다.\"\n",
        "]\n",
        "\n",
        "print(\"다중 장르 분류 테스트 결과:\")\n",
        "print(\"-\" * 50)\n",
        "for i, review in enumerate(test_reviews, 1):\n",
        "    predicted_genre = predict_genre_zero_shot(review)\n",
        "    print(f\"{i}. 리뷰: {review}\")\n",
        "    print(f\"   예측 장르: {predicted_genre}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "### 7. 🚀 최종 실습 과제: 나만의 감성 분석 파이프라인 완성하기\n",
        "\n",
        "지금까지 배운 `Kiwipiepy` 전처리, TF-IDF, 지도 학습 기반 임베딩 모델, 그리고 제로샷 분류까지 모두 종합하여, 새로운 영화 리뷰에 대한 감성을 예측하는 완전한 파이프라인을 구축해봅시다.\n",
        "\n",
        "아래 `predict_sentiment_pipeline` 함수를 완성하세요. 이 함수는 `method` 인자에 따라 'tfidf', 'openai_logistic', 'openai_zero_shot' 세 가지 방식을 선택하여 예측을 수행해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이 셀을 실행하기 전에, 위에서 모든 모델과 벡터라이저가 준비되었다고 가정합니다.\n",
        "\n",
        "# 제로샷 예측을 위해 레이블 임베딩을 미리 계산해 둡니다.\n",
        "positive_label_text = \"매우 긍정적이고 좋은 평가\"\n",
        "negative_label_text = \"매우 부정적이고 나쁜 평가\"\n",
        "positive_embedding = get_embedding(positive_label_text)\n",
        "negative_embedding = get_embedding(negative_label_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(random_state=42, C=5, max_iter=1000)\n",
        "\n",
        "lr_model.fit(train_200_df_emb['large_embedding'].tolist(), train_200_df_emb['label'].tolist())\n",
        "\n",
        "y_pred_large_model = lr_model.predict(test_200_df_emb['large_embedding'].tolist())\n",
        "\n",
        "print(f\"Large Embedding 모델 정확도: {accuracy_score(test_200_df_emb['label'].tolist(), y_pred_large_model)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_sentiment_pipeline(review_text, method='openai_zero_shot'):\n",
        "    \"\"\"\n",
        "    새로운 영화 리뷰의 감성을 예측하는 파이프라인 함수\n",
        "\n",
        "    Args:\n",
        "        review_text (str): 감성 분석을 수행할 영화 리뷰 텍스트.\n",
        "        method (str): 'tfidf', 'openai_logistic', 'openai_zero_shot' 중 사용할 예측 방식을 선택.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (예측 레이블(0 or 1), 예측 결과('긍정' or '부정'))\n",
        "    \"\"\"\n",
        "    # 1. 텍스트 전처리\n",
        "    preprocessed_text = kiwi_preprocess(review_text)\n",
        "\n",
        "    if method == 'tfidf':\n",
        "        if 'lr_model' not in globals(): return None, \"오류: TF-IDF 모델이 학습되지 않았습니다.\"\n",
        "        vectorized_text = tfidf_vectorizer.transform([preprocessed_text])\n",
        "        prediction = lr_model.predict(vectorized_text)\n",
        "\n",
        "    elif method == 'openai_logistic':\n",
        "        if 'lr_model_emb' not in globals(): return None, \"오류: 지도학습 임베딩 모델이 학습되지 않았습니다.\"\n",
        "        embedding_vector = get_embedding(preprocessed_text)\n",
        "        if embedding_vector is None: return None, \"오류: 임베딩 생성 실패\"\n",
        "        vectorized_text = np.array([embedding_vector])\n",
        "        prediction = lr_model_emb.predict(vectorized_text)\n",
        "\n",
        "    elif method == 'openai_zero_shot':\n",
        "        if not all([positive_embedding, negative_embedding]): return None, \"오류: 레이블 임베딩이 준비되지 않았습니다.\"\n",
        "        review_embedding = get_embedding(preprocessed_text)\n",
        "        if review_embedding is None: return None, \"오류: 리뷰 임베딩 생성 실패\"\n",
        "\n",
        "        sim_pos = cosine_similarity(review_embedding, positive_embedding)\n",
        "        sim_neg = cosine_similarity(review_embedding, negative_embedding)\n",
        "\n",
        "        prediction = np.array([1 if sim_pos > sim_neg else 0])\n",
        "\n",
        "    else:\n",
        "        return None, \"오류: 'tfidf', 'openai_logistic', 'openai_zero_shot' 방식을 선택해주세요.\"\n",
        "\n",
        "    result_text = '긍정' if prediction[0] == 1 else '부정'\n",
        "    return prediction[0], result_text\n",
        "\n",
        "# 모델 학습이 완료된 후 아래 코드를 실행하여 테스트해보세요.\n",
        "if 'lr_model' in globals() and 'lr_model_emb' in globals():\n",
        "    my_review1 = \"이 영화는 정말 시간 가는 줄 모르고 봤네요. 배우들 연기가 일품입니다!\"\n",
        "    my_review2 = \"기대하고 봤는데 너무 지루했어요. 스토리가 너무 뻔합니다.\"\n",
        "\n",
        "    print(\"--- 예측 테스트 ---\")\n",
        "    label, text = predict_sentiment_pipeline(my_review1, method='tfidf')\n",
        "    print(f\"리뷰: '{my_review1}' (TF-IDF)\\n>> 예측: {text} ({label})\\n\")\n",
        "\n",
        "    label, text = predict_sentiment_pipeline(my_review1, method='openai_logistic')\n",
        "    print(f\"리뷰: '{my_review1}' (지도학습 임베딩)\\n>> 예측: {text} ({label})\\n\")\n",
        "\n",
        "    label, text = predict_sentiment_pipeline(my_review1, method='openai_zero_shot')\n",
        "    print(f\"리뷰: '{my_review1}' (제로샷 임베딩)\\n>> 예측: {text} ({label})\\n\")\n",
        "\n",
        "    label, text = predict_sentiment_pipeline(my_review2, method='openai_zero_shot')\n",
        "    print(f\"리뷰: '{my_review2}' (제로샷 임베딩)\\n>> 예측: {text} ({label})\")\n",
        "else:\n",
        "    print(\"🚨 모델이 아직 학습되지 않았습니다. 이전 코드 셀들을 먼저 실행해주세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuMIswhhHAun"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
