{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1\\. 시계열 데이터의 이해와 정상성 (Understanding Time Series & Stationarity)\n",
        "\n",
        "### 💡 개념 (Concept)\n",
        "\n",
        "\\*\\*시계열 데이터(Time Series Data)\\*\\*란 일정 시간 간격으로 측정된 데이터의 순차적인 집합을 의미합니다. 주식 가격, 월별 강수량, 일일 웹사이트 방문자 수 등이 모두 시계열 데이터의 예입니다.\n",
        "\n",
        "시계열 분석의 핵심 목표는 데이터에 숨겨진 패턴을 발견하고 이를 바탕으로 미래 값을 예측하는 것입니다. 대부분의 시계열 예측 모델은 데이터가 \\*\\*정상성(Stationarity)\\*\\*을 갖는다고 가정합니다.\n",
        "\n",
        "**정상성이란?**\n",
        "시간이 흘러도 데이터의 통계적 특성(평균, 분산 등)이 변하지 않는 상태를 의미합니다. 즉, 시계열 데이터의 분포가 시간에 따라 일정해야 합니다.\n",
        "\n",
        "  * **왜 정상성이 중요한가?**: 데이터의 패턴이 시간과 관계없이 일정해야 과거의 패턴을 기반으로 미래를 안정적으로 예측할 수 있기 때문입니다.\n",
        "  * **비정상 데이터**: 주가처럼 지속적으로 상승하는 추세(Trend)가 있거나, 아이스크림 판매량처럼 계절에 따라 주기적으로 변동하는 계절성(Seasonality)이 있는 데이터는 비정상 시계열입니다.\n",
        "\n",
        "**정상성 확인 방법: ADF 검정 (Augmented Dickey-Fuller Test)**\n",
        "ADF 검정은 시계열 데이터의 정상성을 통계적으로 확인하는 대표적인 방법입니다. 가설은 다음과 같습니다.\n",
        "\n",
        "  * **귀무가설(Null Hypothesis)**: 데이터에 단위근(unit root)이 존재한다. (즉, 비정상 시계열이다)\n",
        "  * **대립가설(Alternative Hypothesis)**: 데이터가 정상성을 만족한다.\n",
        "\n",
        "검정 결과로 나오는 **p-value**가 특정 유의수준(보통 0.05)보다 작으면 귀무가설을 기각하고, 데이터가 정상성을 갖는다고 판단할 수 있습니다.\n",
        "\n",
        "**비정상 데이터를 정상 데이터로 변환하기: 차분 (Differencing)**\n",
        "대부분의 비정상 시계열은 **차분**을 통해 정상성을 만족하는 데이터로 변환할 수 있습니다. 차분은 현재 시점의 데이터에서 바로 이전 시점의 데이터를 빼주는 간단한 과정입니다. 이를 통해 데이터의 추세를 제거하는 효과를 얻을 수 있습니다.\n",
        "\n",
        "$$Y'_t = Y_t - Y_{t-1}$$\n",
        "\n",
        "### 💻 예시 코드 (Example Code)\n",
        "\n",
        "항공 승객 수 데이터를 활용하여 시계열 데이터의 특징을 시각화하고, ADF 검정과 차분을 실습해 보겠습니다."
      ],
      "metadata": {
        "id": "kOVoCH545s_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# 1. 데이터 로드 및 시각화\n",
        "# 웹에서 바로 데이터를 불러옵니다.\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "df = pd.read_csv(url, index_col='Month', parse_dates=True)\n",
        "df.columns = ['Passengers']\n",
        "\n",
        "# 시계열 데이터 플롯\n",
        "fig = px.line(df, x=df.index, y='Passengers', title='월별 항공 승객 수 (1949-1960)')\n",
        "fig.show()\n",
        "\n",
        "# 2. ADF 검정 함수 정의 및 정상성 확인\n",
        "def adf_test(series, name=''):\n",
        "    \"\"\"주어진 시계열에 대해 ADF 검정을 수행하고 결과를 출력합니다.\"\"\"\n",
        "    print(f'>>> {name} ADF Test <<<')\n",
        "    result = adfuller(series.dropna()) # NaN 값을 제외하고 검정 수행\n",
        "    labels = ['ADF Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used']\n",
        "    for value, label in zip(result, labels):\n",
        "        print(label + ' : ' + str(value))\n",
        "\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"=> p-value가 0.05보다 작으므로, 귀무가설을 기각합니다. 데이터는 정상성을 만족합니다.\\n\")\n",
        "    else:\n",
        "        print(\"=> p-value가 0.05보다 크므로, 귀무가설을 기각할 수 없습니다. 데이터는 비정상 시계열입니다.\\n\")\n",
        "\n",
        "# 원본 데이터에 대한 ADF 검정\n",
        "adf_test(df['Passengers'], name='Original')\n",
        "\n",
        "# 3. 1차 차분을 통한 정상성 확보\n",
        "df['Passengers_diff'] = df['Passengers'].diff()\n",
        "\n",
        "# 1차 차분 데이터 플롯\n",
        "fig_diff = px.line(df, x=df.index, y='Passengers_diff', title='1차 차분된 항공 승객 수')\n",
        "fig_diff.show()\n",
        "\n",
        "# 1차 차분 데이터에 대한 ADF 검정\n",
        "adf_test(df['Passengers_diff'], name='1st Differenced')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "-IDkbQVb5s_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  미국 월별 천연가스 판매량 데이터를 불러와 시계열 그래프로 시각화하고, 데이터의 특징(추세, 계절성)을 설명해보세요.\n",
        "      * 데이터셋 URL: `https://raw.githubusercontent.com/plotly/datasets/master/monthly-natural-gas-sales-in-the-us.csv`\n",
        "2.  위 데이터에 대해 ADF 검정을 수행하고 정상성을 만족하는지 확인하세요.\n",
        "3.  데이터가 비정상 시계열이라면, 정상성을 만족할 때까지 차분을 수행하고, 매 차분 단계마다 ADF 검정 결과와 시계열 그래프를 확인하여 비교 설명하세요.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "STAELnVh5s_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 문제 1, 2, 3번 풀이 공간\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# 1. 데이터 로드 및 시각화\n",
        "url_gas = 'https://raw.githubusercontent.com/plotly/datasets/master/monthly-natural-gas-sales-in-the-us.csv'\n",
        "df_gas = pd.read_csv(url_gas, index_col='Month', parse_dates=True)\n",
        "\n",
        "# 여기에 코드를 작성하여 시각화 및 특징을 설명하세요.\n",
        "\n",
        "\n",
        "# 2. ADF 검정 수행\n",
        "# 여기에 코드를 작성하여 원본 데이터의 정상성을 확인하세요.\n",
        "\n",
        "\n",
        "# 3. 차분 및 정상성 확보\n",
        "# 여기에 코드를 작성하여 차분을 적용하고 정상성을 확인하세요."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "LqIBQiVR5s_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 2\\. 단변량 시계열 분석 (Univariate Analysis): ARIMA\n",
        "\n",
        "### 💡 개념 (Concept)\n",
        "\n",
        "**ARIMA(AutoRegressive Integrated Moving Average)** 모델은 가장 대표적인 단변량 시계열 예측 모델입니다. 즉, 하나의 변수(y)의 과거 데이터 패턴과 오차를 학습하여 미래 값을 예측합니다. ARIMA는 세 가지 핵심 요소로 구성됩니다.\n",
        "\n",
        "  * **AR (AutoRegressive, 자기회귀)**: **과거의 값**이 현재의 값에 영향을 미친다는 아이디어에 기반합니다.\n",
        "\n",
        "      * `p`는 참고할 과거 시점의 개수를 의미합니다. (예: `p=3`이면 3개월 전 데이터까지 참고)\n",
        "      * 메타포: \"이번 달 매출은 지난달과 지지난달 매출과 비슷할 거야.\"\n",
        "        $$Y_t = \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + \\epsilon_t$$\n",
        "\n",
        "  * **I (Integrated, 통합)**: 비정상 시계열을 정상 시계열로 만들기 위해 필요한 **차분 횟수**를 의미합니다.\n",
        "\n",
        "      * `d`는 차분을 적용한 횟수를 나타냅니다. (d=1이면 1차 차분)\n",
        "\n",
        "  * **MA (Moving Average, 이동평균)**: **과거의 예측 오차**가 현재의 값에 영향을 미친다는 개념입니다.\n",
        "\n",
        "      * `q`는 참고할 과거 예측 오차의 개수를 의미합니다.\n",
        "      * 메타포: \"지난달 매출 예측이 빗나갔으니, 그 오차를 반영해서 이번 달 예측을 보정해야 해.\"\n",
        "        $$Y_t = \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q}$$\n",
        "\n",
        "**ACF와 PACF: p와 q 정하기**\n",
        "ARIMA 모델의 차수 `p`와 `q`를 결정하기 위해 \\*\\*ACF(자기상관함수)\\*\\*와 **PACF(부분자기상관함수)** 플롯을 활용합니다.\n",
        "\n",
        "  * **ACF (Autocorrelation Function)**: 시점 t의 데이터와 그 이전 시점들(t-1, t-2, ...)의 데이터 간의 상관관계를 보여줍니다. **MA 모델의 차수 q를 결정**하는 데 사용됩니다.\n",
        "  * **PACF (Partial Autocorrelation Function)**: 다른 시점들의 영향을 제외하고, 오직 두 시점(t와 t-k)의 데이터 간 순수한 상관관계를 보여줍니다. **AR 모델의 차수 p를 결정**하는 데 사용됩니다.\n",
        "\n",
        "| 모델 | ACF 플롯 특징 | PACF 플롯 특징 |\n",
        "| :--- | :--- | :--- |\n",
        "| **AR(p)** | 점차 감소하며 0에 수렴 | `p` 시점 이후 급격히 0으로 절단 |\n",
        "| **MA(q)** | `q` 시점 이후 급격히 0으로 절단 | 점차 감소하며 0에 수렴 |\n",
        "\n",
        "### 💻 예시 코드 (Example Code)\n",
        "\n",
        "이번에는 `moneystock-spending-series.csv` 데이터셋을 사용하여 ARIMA 모델을 구축하고 예측을 수행합니다. 이 데이터는 M2 통화량과 개인 소비 지출 데이터로 구성되어 있습니다."
      ],
      "metadata": {
        "id": "u00FYsuQ5s_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 로드 (money stock spending)\n",
        "df_money = pd.read_csv('https://raw.githubusercontent.com/datamanim/datarepo/main/tsa/moneystock-spending-series.csv', index_col=0, parse_dates=True)\n",
        "df_money.index.freq = 'MS' # 월별 데이터 주파수 설정\n",
        "\n",
        "# 'Money' 변수에 대해 분석 진행\n",
        "money_series = df_money['Money']\n",
        "\n",
        "# 1. 정상성 확인 및 차분\n",
        "# ADF 검정 결과 p-value가 1.0으로 비정상 시계열임 (위에서 실습)\n",
        "# 2차 차분을 통해 정상성 확보\n",
        "money_diff2 = money_series.diff().diff().dropna()\n",
        "# adf_test(money_diff2) # p-value가 매우 작게 나와 정상성 만족\n",
        "\n",
        "# 2. ACF, PACF 플롯으로 p, q 추정\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "plot_acf(money_diff2, ax=ax1)\n",
        "plot_pacf(money_diff2, ax=ax2)\n",
        "plt.show()\n",
        "# PACF 플롯을 보면 lag 1 이후에 값이 급격히 감소하므로 p=1로 추정 가능\n",
        "# ACF 플롯을 보면 lag 1 이후에 값이 급격히 감소하므로 q=1로 추정 가능\n",
        "\n",
        "# 3. ARIMA(1, 2, 1) 모델 구축 및 학습\n",
        "# p=1, d=2(2차 차분), q=1\n",
        "model = ARIMA(money_series, order=(1, 2, 1))\n",
        "fitted_model = model.fit()\n",
        "print(fitted_model.summary())\n",
        "\n",
        "# 4. 예측 및 시각화\n",
        "# 학습 데이터 분할 (마지막 12개월을 테스트 데이터로)\n",
        "train_data = money_series[:-12]\n",
        "test_data = money_series[-12:]\n",
        "\n",
        "# ARIMA(1, 2, 1) 모델 재학습\n",
        "model_train = ARIMA(train_data, order=(1, 2, 1))\n",
        "fitted_train_model = model_train.fit()\n",
        "\n",
        "# 예측 (12개월)\n",
        "forecast = fitted_train_model.forecast(steps=12)\n",
        "\n",
        "# 결과 시각화\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=train_data.index, y=train_data, name='Train'))\n",
        "fig.add_trace(go.Scatter(x=test_data.index, y=test_data, name='Test'))\n",
        "fig.add_trace(go.Scatter(x=forecast.index, y=forecast, name='Forecast'))\n",
        "fig.update_layout(title='M2 통화량: 실제값 vs 예측값 (ARIMA)', xaxis_title='날짜', yaxis_title='통화량')\n",
        "fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "uAvqnLrJ5s_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  미국 월별 주택 판매량 데이터를 사용하여 미래 12개월을 예측하는 ARIMA 모델을 만들어보세요.\n",
        "      * 데이터셋 URL: `https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-housing-starts.csv`\n",
        "2.  데이터를 로드하고 시각화하여 패턴을 확인한 후, 정상성을 확보하기 위해 몇 번의 차분이 필요한지 결정하세요.\n",
        "3.  정상화된 데이터에 대해 ACF, PACF 플롯을 그려보고, 적절한 `p`와 `q` 값을 추론해보세요.\n",
        "4.  추론한 `p, d, q` 값을 사용하여 ARIMA 모델을 구축하고, 예측 결과를 실제값과 함께 그래프로 비교해보세요.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "LPqk3Xs35s_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 문제 1, 2, 3, 4번 풀이 공간\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 데이터 로드\n",
        "url_housing = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-housing-starts.csv'\n",
        "df_housing = pd.read_csv(url_housing, index_col=0, parse_dates=True)\n",
        "df_housing.columns = ['Starts']\n",
        "\n",
        "# 여기에 2, 3, 4번 문제에 대한 코드를 작성하세요."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "0P3D2mDB5s_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 3\\. 계절성을 고려한 시계열 분석 (Seasonal Analysis): SARIMA\n",
        "\n",
        "### 💡 개념 (Concept)\n",
        "\n",
        "현실의 많은 시계열 데이터는 **계절성(Seasonality)**, 즉 특정 기간(주, 월, 분기, 년 등)을 주기로 반복되는 패턴을 가집니다. **SARIMA(Seasonal ARIMA)** 모델은 기존 ARIMA 모델에 이러한 계절적 요인을 추가하여 예측 성능을 높인 모델입니다.\n",
        "\n",
        "SARIMA 모델은 `ARIMA(p,d,q)`에 계절성 요소를 나타내는 `(P,D,Q,s)`가 추가됩니다.\n",
        "\n",
        "  * **`s`**: 계절 주기를 의미합니다. (예: 월별 데이터면 `s=12`, 분기별 데이터면 `s=4`)\n",
        "  * **`P`**: 계절성 자기회귀(Seasonal AR) 차수. `s` 기간 전의 과거 값이 현재 값에 미치는 영향을 나타냅니다.\n",
        "  * **`D`**: 계절성 차분(Seasonal Differencing) 횟수. 계절성 패턴을 제거하기 위해 필요한 차분 횟수입니다.\n",
        "  * **`Q`**: 계절성 이동평균(Seasonal MA) 차수. `s` 기간 전의 과거 예측 오차가 현재 값에 미치는 영향을 나타냅니다.\n",
        "\n",
        "메타포: \"올해 8월의 아이스크림 판매량은 작년 8월 판매량과 작년 예측 오차에 영향을 받을 것이다.\"\n",
        "\n",
        "**Auto-ARIMA: 최적의 파라미터 자동 탐색**\n",
        "SARIMA 모델은 `(p,d,q)(P,D,Q,s)`라는 7개의 파라미터를 결정해야 하므로, ACF/PACF만으로 최적의 조합을 찾기 어렵습니다. 이때 **`auto_arima`** 함수를 사용하면 매우 편리합니다. `auto_arima`는 주어진 데이터에 대해 다양한 파라미터 조합을 시도하고, **AIC(Akaike Information Criterion)** 값이 가장 낮은 최적의 모델을 자동으로 찾아줍니다.\n",
        "\n",
        "### 💻 예시 코드 (Example Code)\n",
        "\n",
        "`auto_arima`를 사용하여 월별 항공 승객 수 데이터에 대한 최적의 SARIMA 모델을 찾고, 예측을 수행해 보겠습니다."
      ],
      "metadata": {
        "id": "m1sqhdc85s_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pmdarima 라이브러리가 필요합니다.\n",
        "# !pip install pmdarima\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import pmdarima as pm\n",
        "from pmdarima.model_selection import train_test_split\n",
        "\n",
        "# 데이터 로드\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "df = pd.read_csv(url, index_col='Month', parse_dates=True)\n",
        "df.columns = ['Passengers']\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "train_auto, test_auto = train_test_split(df['Passengers'], train_size=len(df)-12)\n",
        "\n",
        "# auto_arima로 최적 모델 탐색\n",
        "# 계절 주기는 월별 데이터이므로 m=12로 설정합니다.\n",
        "sarima_model = pm.auto_arima(train_auto,\n",
        "                             start_p=1, start_q=1,\n",
        "                             test='adf',       # adf 검정으로 d 결정\n",
        "                             max_p=3, max_q=3,  # p, q 최대값\n",
        "                             m=12,             # 계절 주기\n",
        "                             d=None,           # d는 자동으로 찾도록 설정\n",
        "                             seasonal=True,    # 계절성 모델 사용\n",
        "                             start_P=0,\n",
        "                             D=1,              # 계절성 차분은 1로 고정 (일반적)\n",
        "                             trace=True,       # 모델 탐색 과정 출력\n",
        "                             error_action='ignore',\n",
        "                             suppress_warnings=True,\n",
        "                             stepwise=True)     # 최적 파라미터를 효율적으로 찾음\n",
        "\n",
        "print(sarima_model.summary())\n",
        "\n",
        "# 테스트 데이터에 대한 예측\n",
        "n_periods = 12\n",
        "forecast_auto, conf_int = sarima_model.predict(n_periods=n_periods, return_conf_int=True)\n",
        "\n",
        "# 예측 결과 시각화\n",
        "forecast_index = pd.date_range(start=train_auto.index[-1] + pd.DateOffset(months=1), periods=n_periods, freq='MS')\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df['Passengers'], name='Actual'))\n",
        "fig.add_trace(go.Scatter(x=forecast_index, y=forecast_auto, name='Forecast'))\n",
        "\n",
        "# 신뢰구간 추가\n",
        "fig.add_trace(go.Scatter(x=forecast_index, y=conf_int[:, 0], fill='tonexty',\n",
        "                         mode='lines', line_color='rgba(255,0,0,0.1)', name='Lower CI'))\n",
        "fig.add_trace(go.Scatter(x=forecast_index, y=conf_int[:, 1], fill='tonexty',\n",
        "                         mode='lines', line_color='rgba(255,0,0,0.1)', name='Upper CI'))\n",
        "\n",
        "fig.update_layout(title='항공 승객 수 예측 (SARIMA with auto_arima)', xaxis_title='날짜', yaxis_title='승객 수')\n",
        "fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "hsTQlxkb5s_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  샴푸 판매량 데이터는 36개월간의 월별 판매량을 기록하고 있습니다. 이 데이터를 사용하여 SARIMA 모델을 구축해보세요.\n",
        "      * 데이터셋 URL: `https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv`\n",
        "2.  데이터에 계절성이 있는지 시각적으로 확인해보세요. (힌트: 12개월 주기로 패턴이 나타나는지 확인)\n",
        "3.  `auto_arima`를 사용하여 최적의 SARIMA 모델을 찾고, 그 결과를 해석해보세요. (계절 주기는 12로 설정)\n",
        "4.  마지막 6개월을 예측하고, 실제 데이터와 비교하여 모델의 성능을 시각적으로 평가해보세요.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "uZ85q9sp5s_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 문제 1, 2, 3, 4번 풀이 공간\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import pmdarima as pm\n",
        "from pmdarima.model_selection import train_test_split\n",
        "\n",
        "# 1. 데이터 로드\n",
        "url_shampoo = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv'\n",
        "df_shampoo = pd.read_csv(url_shampoo, index_col='Month', parse_dates=True)\n",
        "df_shampoo.columns = ['Sales']\n",
        "\n",
        "\n",
        "# 여기에 2, 3, 4번 문제에 대한 코드를 작성하세요."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "oZakUvZ35s_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 4\\. 다변량 시계열 분석 (Multivariate Analysis): VAR\n",
        "\n",
        "### 💡 개념 (Concept)\n",
        "\n",
        "**VAR(Vector AutoRegression, 벡터 자기회귀)** 모델은 **여러 개의 시계열 변수**가 서로 영향을 주고받는 관계를 모델링하는 **다변량(Multivariate)** 시계열 분석 기법입니다.\n",
        "\n",
        "단변량 분석(ARIMA 등)이 하나의 변수(y)의 과거만을 보고 미래를 예측했다면, VAR은 여러 변수(y1, y2, ...)의 과거 값들이 서로의 현재 값에 어떻게 영향을 미치는지를 동시에 분석합니다.\n",
        "\n",
        "메타포: \"오늘의 기온(y1)은 어제의 기온뿐만 아니라 어제의 풍속(y2)과 습도(y3)에도 영향을 받는다.\"\n",
        "\n",
        "**VAR 모델의 특징**:\n",
        "\n",
        "  * **내생성**: 모델에 포함된 모든 변수는 서로에게 영향을 주는 내생변수(endogenous variable)로 취급됩니다.\n",
        "  * **방정식 시스템**: 각 변수에 대해 별도의 회귀 방정식이 만들어집니다. 예를 들어, 변수가 2개(y1, y2)인 VAR(1) 모델은 다음과 같은 두 개의 방정식으로 구성됩니다.\n",
        "    $$y_{1,t} = c_1 + \\phi_{11,1}y_{1,t-1} + \\phi_{12,1}y_{2,t-1} + \\epsilon_{1,t}$$\n",
        "    $$y_{2,t} = c_2 + \\phi_{21,1}y_{1,t-1} + \\phi_{22,1}y_{2,t-1} + \\epsilon_{2,t}$$\n",
        "  * **정상성**: VAR 모델 역시 모든 시계열 데이터가 정상성을 만족해야 합니다. 따라서 모델링 전에 각 변수에 대해 ADF 검정 및 차분을 수행해야 합니다.\n",
        "  * **최적 시차(p) 결정**: AIC, BIC 등의 정보 기준을 사용하여 최적의 시차 `p`를 결정합니다.\n",
        "\n",
        "**VARMA, VARMAX 란?**\n",
        "\n",
        "  * **VARMA**: VAR 모델에 이동평균(MA) 항을 추가하여, 각 변수의 예측 오차 또한 다른 변수들에게 영향을 미치는 관계를 모델링합니다.\n",
        "  * **VARMAX**: VARMA 모델에 외생변수(eXogenous variable, X)를 추가한 모델입니다. 모델 외부에서 결정되지만 모델 내 변수들에게 영향을 주는 변수(예: 정책, 이벤트)를 분석에 포함시킬 수 있습니다.\n",
        "\n",
        "### 💻 예시 코드 (Example Code)\n",
        "\n",
        "`moneystock-spending-series.csv` 데이터의 'Money'와 'Spending' 두 변수가 서로에게 미치는 영향을 VAR 모델로 분석해 보겠습니다."
      ],
      "metadata": {
        "id": "WNvR9rlU5s_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# 데이터 로드 및 2차 차분 (정상성 확보)\n",
        "df_money = pd.read_csv('https://raw.githubusercontent.com/datamanim/datarepo/main/tsa/moneystock-spending-series.csv', index_col=0, parse_dates=True)\n",
        "df_money.index.freq = 'MS'\n",
        "df_diff2 = df_money.diff().diff().dropna()\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 분리\n",
        "nobs = 12 # 마지막 12개를 테스트 데이터로 사용\n",
        "train_var = df_diff2[:-nobs]\n",
        "test_var = df_diff2[-nobs:]\n",
        "\n",
        "# 1. 최적의 시차 p 찾기\n",
        "model_var = VAR(train_var)\n",
        "lag_selection_results = model_var.select_order(maxlags=15)\n",
        "print(lag_selection_results.summary())\n",
        "# AIC 기준 최적 시차는 5로 나타남\n",
        "\n",
        "# 2. VAR(5) 모델 구축 및 학습\n",
        "model_fitted = model_var.fit(5)\n",
        "print(model_fitted.summary())\n",
        "\n",
        "# 3. 예측\n",
        "lag_order = model_fitted.k_ar\n",
        "forecast_input = train_var.values[-lag_order:]\n",
        "forecast_var = model_fitted.forecast(y=forecast_input, steps=nobs)\n",
        "df_forecast = pd.DataFrame(forecast_var, index=test_var.index, columns=train_var.columns + '_2d')\n",
        "\n",
        "# 4. 예측 결과 역변환 (Invert Differencing)\n",
        "def invert_transformation(df_train, df_forecast, second_diff=False):\n",
        "    \"\"\"차분된 예측값을 원본 스케일로 복원합니다.\"\"\"\n",
        "    df_fc = df_forecast.copy()\n",
        "    columns = df_train.columns\n",
        "    for col in columns:\n",
        "        # 1차 차분 복원\n",
        "        df_fc[str(col)+'_1d'] = (df_train[col].iloc[-1] - df_train[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
        "        # 2차 차분 복원\n",
        "        df_fc[str(col)+'_forecast'] = df_train[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
        "    return df_fc\n",
        "\n",
        "df_results = invert_transformation(df_money[['Money', 'Spending']], df_forecast)\n",
        "\n",
        "# 5. 결과 시각화\n",
        "fig = go.Figure()\n",
        "# Money 변수\n",
        "fig.add_trace(go.Scatter(x=df_money.index, y=df_money['Money'], name='Money Actual'))\n",
        "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['Money_forecast'], name='Money Forecast', line=dict(dash='dot')))\n",
        "# Spending 변수\n",
        "fig.add_trace(go.Scatter(x=df_money.index, y=df_money['Spending'], name='Spending Actual'))\n",
        "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['Spending_forecast'], name='Spending Forecast', line=dict(dash='dot')))\n",
        "\n",
        "fig.update_layout(title='M2 통화량 및 개인 소비 지출 예측 (VAR)', xaxis_title='날짜')\n",
        "fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JD4VI_gE5s_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏️ 연습 문제 (Practice Problems)\n",
        "\n",
        "1.  캐나다의 거시경제 데이터(고용, 생산성, 실업률, 인구)를 사용하여 VAR 모델을 구축해보세요.\n",
        "      * 데이터셋 URL: `https://raw.githubusercontent.com/statsmodels/statsmodels/main/statsmodels/datasets/macrodata/macrodata.csv`\n",
        "      * 데이터셋은 분기별 데이터입니다. 'year'와 'quarter' 열을 조합하여 시계열 인덱스를 만드세요.\n",
        "2.  모델에 사용할 변수('e', 'prod', 'unemp', 'pop')를 선택하고, 각 변수의 정상성을 확인한 후 필요하다면 차분을 적용하세요.\n",
        "3.  `select_order()`를 사용하여 최적의 시차(lag)를 결정하세요.\n",
        "4.  결정된 시차로 VAR 모델을 학습하고, 향후 8분기(2년)를 예측해보세요. 예측 결과를 역변환하여 원본 스케일로 만들고, 그래프로 시각화하여 실제 데이터의 추세와 비교해보세요.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "DC0iJYgy5s_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 문제 1, 2, 3, 4번 풀이 공간\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "# 1. 데이터 로드 및 인덱스 설정\n",
        "url_macro = 'https://raw.githubusercontent.com/statsmodels/statsmodels/main/statsmodels/datasets/macrodata/macrodata.csv'\n",
        "df_macro = pd.read_csv(url_macro)\n",
        "# 여기에 코드를 작성하여 시계열 인덱스를 생성하세요.\n",
        "\n",
        "\n",
        "# 2. 변수 선택 및 정상성 확인/차분\n",
        "# 여기에 코드를 작성하세요.\n",
        "\n",
        "\n",
        "# 3. 최적 시차 결정\n",
        "# 여기에 코드를 작성하세요.\n",
        "\n",
        "\n",
        "# 4. 모델링, 예측, 역변환 및 시각화\n",
        "# 여기에 코드를 작성하세요."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Cj59mD6o5s_7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}