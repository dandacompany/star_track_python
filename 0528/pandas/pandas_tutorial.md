# ğŸ¼ Pandas ì™„ì „ ì •ë³µ íŠœí† ë¦¬ì–¼

## Pandas ì´ˆì¤‘ê¸‰ì—ì„œ ì¤‘ê³ ê¸‰ìœ¼ë¡œ ë„ì•½í•˜ëŠ” ë‹¨í…Œ ê°€ì´ë“œ

> **ğŸ“ ë°ì´í„°ì…‹ ì¤€ë¹„**: íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì— `datasets` í´ë”ì—ì„œ `python create_all_datasets.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

---

## ğŸ“š ëª©ì°¨

- [ğŸ¼ Pandas ì™„ì „ ì •ë³µ íŠœí† ë¦¬ì–¼](#-pandas-ì™„ì „-ì •ë³µ-íŠœí† ë¦¬ì–¼)
  - [Pandas ì´ˆì¤‘ê¸‰ì—ì„œ ì¤‘ê³ ê¸‰ìœ¼ë¡œ ë„ì•½í•˜ëŠ” ë‹¨í…Œ ê°€ì´ë“œ](#pandas-ì´ˆì¤‘ê¸‰ì—ì„œ-ì¤‘ê³ ê¸‰ìœ¼ë¡œ-ë„ì•½í•˜ëŠ”-ë‹¨í…Œ-ê°€ì´ë“œ)
  - [ğŸ“š ëª©ì°¨](#-ëª©ì°¨)
  - [ê¸°ë³¸í¸](#ê¸°ë³¸í¸)
    - [Pandas ì†Œê°œ ë° ì„¤ì¹˜](#pandas-ì†Œê°œ-ë°-ì„¤ì¹˜)
      - [ì„¤ì¹˜ ë° ì„í¬íŠ¸](#ì„¤ì¹˜-ë°-ì„í¬íŠ¸)
    - [Seriesì™€ DataFrame ê¸°ì´ˆ](#seriesì™€-dataframe-ê¸°ì´ˆ)
      - [Series ìƒì„±ê³¼ ê¸°ë³¸ ì¡°ì‘](#series-ìƒì„±ê³¼-ê¸°ë³¸-ì¡°ì‘)
      - [Seriesì˜ ê¸°ë³¸ ì†ì„±ê³¼ ë©”ì„œë“œ](#seriesì˜-ê¸°ë³¸-ì†ì„±ê³¼-ë©”ì„œë“œ)
      - [DataFrame ìƒì„±ê³¼ ê¸°ë³¸ ì¡°ì‘](#dataframe-ìƒì„±ê³¼-ê¸°ë³¸-ì¡°ì‘)
      - [DataFrameì˜ ê¸°ë³¸ ì •ë³´ í™•ì¸](#dataframeì˜-ê¸°ë³¸-ì •ë³´-í™•ì¸)
    - [ë°ì´í„° ì½ê¸°/ì“°ê¸°](#ë°ì´í„°-ì½ê¸°ì“°ê¸°)
      - [CSV íŒŒì¼ ë‹¤ë£¨ê¸°](#csv-íŒŒì¼-ë‹¤ë£¨ê¸°)
      - [Excel íŒŒì¼ ë‹¤ë£¨ê¸°](#excel-íŒŒì¼-ë‹¤ë£¨ê¸°)
    - [ê¸°ë³¸ ë°ì´í„° ì¡°ì‘](#ê¸°ë³¸-ë°ì´í„°-ì¡°ì‘)
      - [ì»¬ëŸ¼ ì„ íƒê³¼ ì¶”ê°€](#ì»¬ëŸ¼-ì„ íƒê³¼-ì¶”ê°€)
      - [í–‰ ì„ íƒê³¼ í•„í„°ë§](#í–‰-ì„ íƒê³¼-í•„í„°ë§)
      - [ì •ë ¬](#ì •ë ¬)
  - [ì¤‘ê¸‰í¸](#ì¤‘ê¸‰í¸)
    - [ê³ ê¸‰ ì¸ë±ì‹±ê³¼ ì„ íƒ](#ê³ ê¸‰-ì¸ë±ì‹±ê³¼-ì„ íƒ)
      - [.locì™€ .iloc í™œìš©](#locì™€-iloc-í™œìš©)
      - [ì¡°ê±´ë¶€ ì„ íƒê³¼ query ë©”ì„œë“œ](#ì¡°ê±´ë¶€-ì„ íƒê³¼-query-ë©”ì„œë“œ)
    - [ë°ì´í„° ì •ì œì™€ ë³€í™˜](#ë°ì´í„°-ì •ì œì™€-ë³€í™˜)
      - [ê²°ì¸¡ê°’ ì²˜ë¦¬](#ê²°ì¸¡ê°’-ì²˜ë¦¬)
      - [ë°ì´í„° íƒ€ì… ë³€í™˜](#ë°ì´í„°-íƒ€ì…-ë³€í™˜)
      - [applyì™€ map í•¨ìˆ˜ í™œìš©](#applyì™€-map-í•¨ìˆ˜-í™œìš©)
    - [ê·¸ë£¹í™”ì™€ ì§‘ê³„](#ê·¸ë£¹í™”ì™€-ì§‘ê³„)
      - [ê¸°ë³¸ ê·¸ë£¹í™”](#ê¸°ë³¸-ê·¸ë£¹í™”)
      - [ë‹¤ì¤‘ ê·¸ë£¹í™”ì™€ ì§‘ê³„](#ë‹¤ì¤‘-ê·¸ë£¹í™”ì™€-ì§‘ê³„)
      - [transformê³¼ filter í™œìš©](#transformê³¼-filter-í™œìš©)
    - [ë°ì´í„° ë³‘í•©ê³¼ ê²°í•©](#ë°ì´í„°-ë³‘í•©ê³¼-ê²°í•©)
      - [merge í•¨ìˆ˜ í™œìš©](#merge-í•¨ìˆ˜-í™œìš©)
      - [concat í•¨ìˆ˜ í™œìš©](#concat-í•¨ìˆ˜-í™œìš©)
  - [ìµœì‹ ê¸°ëŠ¥í¸](#ìµœì‹ ê¸°ëŠ¥í¸)
    - [PyArrow ë°±ì—”ë“œ í™œìš©](#pyarrow-ë°±ì—”ë“œ-í™œìš©)
    - [ê³ ê¸‰ ë¬¸ìì—´ ì²˜ë¦¬](#ê³ ê¸‰-ë¬¸ìì—´-ì²˜ë¦¬)
    - [ì‹œê³„ì—´ ë°ì´í„° ê³ ê¸‰ ì²˜ë¦¬](#ì‹œê³„ì—´-ë°ì´í„°-ê³ ê¸‰-ì²˜ë¦¬)
    - [ì„±ëŠ¥ ìµœì í™” ê¸°ë²•](#ì„±ëŠ¥-ìµœì í™”-ê¸°ë²•)
      - [ë©”ëª¨ë¦¬ ìµœì í™”](#ë©”ëª¨ë¦¬-ìµœì í™”)
      - [ë²¡í„°í™” ì—°ì‚° í™œìš©](#ë²¡í„°í™”-ì—°ì‚°-í™œìš©)
      - [evalê³¼ queryë¥¼ ì´ìš©í•œ ì„±ëŠ¥ í–¥ìƒ](#evalê³¼-queryë¥¼-ì´ìš©í•œ-ì„±ëŠ¥-í–¥ìƒ)
  - [ğŸ¯ ì‹¤ì „ í”„ë¡œì íŠ¸: ì¢…í•© ë°ì´í„° ë¶„ì„](#-ì‹¤ì „-í”„ë¡œì íŠ¸-ì¢…í•©-ë°ì´í„°-ë¶„ì„)
  - [ğŸ“ ë§ˆë¬´ë¦¬ ë° ì¶”ê°€ í•™ìŠµ ê°€ì´ë“œ](#-ë§ˆë¬´ë¦¬-ë°-ì¶”ê°€-í•™ìŠµ-ê°€ì´ë“œ)
    - [í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬](#í•µì‹¬-í¬ì¸íŠ¸-ì •ë¦¬)
    - [ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ì¶”ì²œ](#ë‹¤ìŒ-ë‹¨ê³„-í•™ìŠµ-ì¶”ì²œ)
    - [ì‹¤ë¬´ íŒ](#ì‹¤ë¬´-íŒ)
  - [ğŸ“Š Plotlyë¥¼ í™œìš©í•œ ë°ì´í„° ì‹œê°í™”](#-plotlyë¥¼-í™œìš©í•œ-ë°ì´í„°-ì‹œê°í™”)
    - [Plotly ì„¤ì¹˜ ë° ê¸°ë³¸ ì„¤ì •](#plotly-ì„¤ì¹˜-ë°-ê¸°ë³¸-ì„¤ì •)
    - [ê¸°ë³¸ ì°¨íŠ¸ ìƒì„±](#ê¸°ë³¸-ì°¨íŠ¸-ìƒì„±)
    - [íŒë§¤ ë°ì´í„° ì‹œê°í™”](#íŒë§¤-ë°ì´í„°-ì‹œê°í™”)
    - [ì£¼ì‹ ë°ì´í„° ì‹œê°í™”](#ì£¼ì‹-ë°ì´í„°-ì‹œê°í™”)
    - [ì„¼ì„œ ë°ì´í„° ì‹œê°í™”](#ì„¼ì„œ-ë°ì´í„°-ì‹œê°í™”)
    - [ê³ ê° ë¶„ì„ ì‹œê°í™”](#ê³ ê°-ë¶„ì„-ì‹œê°í™”)
    - [ëŒ€ì‹œë³´ë“œ ìŠ¤íƒ€ì¼ ì¢…í•© ì°¨íŠ¸](#ëŒ€ì‹œë³´ë“œ-ìŠ¤íƒ€ì¼-ì¢…í•©-ì°¨íŠ¸)
    - [ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥ í™œìš©](#ì¸í„°ë™í‹°ë¸Œ-ê¸°ëŠ¥-í™œìš©)
    - [Plotly ì°¨íŠ¸ ì €ì¥í•˜ê¸°](#plotly-ì°¨íŠ¸-ì €ì¥í•˜ê¸°)
    - [ğŸ“Š ì‹œê°í™” íŒ](#-ì‹œê°í™”-íŒ)

---

## ê¸°ë³¸í¸

### Pandas ì†Œê°œ ë° ì„¤ì¹˜

PandasëŠ” Pythonì—ì„œ ê°€ì¥ ê°•ë ¥í•œ ë°ì´í„° ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#### ì„¤ì¹˜ ë° ì„í¬íŠ¸

```python
# ì„¤ì¹˜ (í„°ë¯¸ë„ì—ì„œ)
# pip install pandas numpy

# ê¸°ë³¸ ì„í¬íŠ¸
import pandas as pd
import numpy as np

# ë²„ì „ í™•ì¸
print(f"Pandas ë²„ì „: {pd.__version__}")
print(f"NumPy ë²„ì „: {np.__version__}")
```

### Seriesì™€ DataFrame ê¸°ì´ˆ

#### Series ìƒì„±ê³¼ ê¸°ë³¸ ì¡°ì‘

SeriesëŠ” pandasì˜ 1ì°¨ì› ë°ì´í„° êµ¬ì¡°ì…ë‹ˆë‹¤. ì¸ë±ìŠ¤ê°€ ìˆëŠ” ë°°ì—´ì´ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.

```python
# ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ Series ìƒì„±
# 1. ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ìƒì„±
s1 = pd.Series([1, 3, 5, 7, 9])
print("ê¸°ë³¸ Series:")
print(s1)

# 2. ì¸ë±ìŠ¤ë¥¼ ì§€ì •í•˜ì—¬ ìƒì„±
s2 = pd.Series([10, 20, 30, 40, 50], 
               index=['a', 'b', 'c', 'd', 'e'])
print("\nì¸ë±ìŠ¤ê°€ ìˆëŠ” Series:")
print(s2)

# 3. ë”•ì…”ë„ˆë¦¬ë¡œë¶€í„° ìƒì„±
data_dict = {'ì„œìš¸': 9776000, 'ë¶€ì‚°': 3419000, 'ëŒ€êµ¬': 2438000}
s3 = pd.Series(data_dict)
print("\në”•ì…”ë„ˆë¦¬ë¡œë¶€í„° ìƒì„±í•œ Series:")
print(s3)
```

#### Seriesì˜ ê¸°ë³¸ ì†ì„±ê³¼ ë©”ì„œë“œ

```python
# Seriesì˜ ê¸°ë³¸ ì •ë³´
print(f"ë°ì´í„° íƒ€ì…: {s3.dtype}")
print(f"ì¸ë±ìŠ¤: {s3.index}")
print(f"ê°’ë“¤: {s3.values}")
print(f"í¬ê¸°: {s3.size}")
print(f"ëª¨ì–‘: {s3.shape}")

# ê¸°ë³¸ í†µê³„ ì •ë³´
print(f"\nê¸°ë³¸ í†µê³„:")
print(f"í‰ê· : {s3.mean():,.0f}")
print(f"ìµœëŒ“ê°’: {s3.max():,.0f}")
print(f"ìµœì†Ÿê°’: {s3.min():,.0f}")
```

#### DataFrame ìƒì„±ê³¼ ê¸°ë³¸ ì¡°ì‘

DataFrameì€ pandasì˜ 2ì°¨ì› ë°ì´í„° êµ¬ì¡°ë¡œ, ì—¬ëŸ¬ ê°œì˜ Seriesê°€ ê²°í•©ëœ í˜•íƒœì…ë‹ˆë‹¤.

```python
# ì‹¤ì œ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('datasets/employees.csv')
print("ì§ì› ì •ë³´ DataFrame:")
print(df)

# ì¸ë±ìŠ¤ ì„¤ì •
df_indexed = df.set_index('ì´ë¦„')
print("\nì´ë¦„ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•œ DataFrame:")
print(df_indexed.head())
```

#### DataFrameì˜ ê¸°ë³¸ ì •ë³´ í™•ì¸

```python
# DataFrame ê¸°ë³¸ ì •ë³´
print("DataFrame ì •ë³´:")
print(f"ëª¨ì–‘: {df.shape}")
print(f"ì»¬ëŸ¼: {list(df.columns)}")
print(f"ì¸ë±ìŠ¤: {list(df.index)}")
print(f"ë°ì´í„° íƒ€ì…:\n{df.dtypes}")

# ì²˜ìŒ ëª‡ í–‰ê³¼ ë§ˆì§€ë§‰ ëª‡ í–‰ í™•ì¸
print("\nì²˜ìŒ 3í–‰:")
print(df.head(3))

print("\në§ˆì§€ë§‰ 2í–‰:")
print(df.tail(2))

# ê¸°ë³¸ í†µê³„ ì •ë³´
print("\nê¸°ë³¸ í†µê³„ ì •ë³´:")
print(df.describe())
```

### ë°ì´í„° ì½ê¸°/ì“°ê¸°

#### CSV íŒŒì¼ ë‹¤ë£¨ê¸°

```python
# ì œí’ˆ ë°ì´í„° ì½ê¸°
df_products = pd.read_csv('datasets/products.csv')
print("ì œí’ˆ ë°ì´í„°:")
print(df_products.head())

# ë‹¤ì–‘í•œ ì½ê¸° ì˜µì…˜
df_custom = pd.read_csv('datasets/products.csv', 
                       usecols=['product_name', 'category', 'price'],  # íŠ¹ì • ì»¬ëŸ¼ë§Œ
                       nrows=10)  # ì²˜ìŒ 10í–‰ë§Œ
print("\nì»¤ìŠ¤í…€ ì½ê¸°:")
print(df_custom)

# ë„ì‹œ ë°ì´í„°ë„ ì½ì–´ë³´ê¸°
df_cities = pd.read_csv('datasets/cities.csv')
print("\në„ì‹œ ë°ì´í„°:")
print(df_cities)
```

#### Excel íŒŒì¼ ë‹¤ë£¨ê¸°

```python
# Excel íŒŒì¼ë¡œ ì €ì¥
df.to_excel('datasets/employee_data.xlsx', index=False, sheet_name='ì§ì›ì •ë³´')

# Excel íŒŒì¼ ì½ê¸°
try:
    df_from_excel = pd.read_excel('datasets/employee_data.xlsx', sheet_name='ì§ì›ì •ë³´')
    print("Excelì—ì„œ ì½ì€ ë°ì´í„°:")
    print(df_from_excel)
except ImportError:
    print("Excel íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ openpyxl ë˜ëŠ” xlrd íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("pip install openpyxl ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
```

### ê¸°ë³¸ ë°ì´í„° ì¡°ì‘

#### ì»¬ëŸ¼ ì„ íƒê³¼ ì¶”ê°€

```python
# ë‹¨ì¼ ì»¬ëŸ¼ ì„ íƒ (Series ë°˜í™˜)
names = df['ì´ë¦„']
print("ì´ë¦„ ì»¬ëŸ¼:")
print(names)
print(f"íƒ€ì…: {type(names)}")

# ì—¬ëŸ¬ ì»¬ëŸ¼ ì„ íƒ (DataFrame ë°˜í™˜)
subset = df[['ì´ë¦„', 'ì—°ë´‰']]
print("\nì´ë¦„ê³¼ ì—°ë´‰:")
print(subset)
print(f"íƒ€ì…: {type(subset)}")

# ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
df['ì—°ë´‰_ë§Œì›'] = df['ì—°ë´‰'] / 10000
df['ê³ ì—°ë´‰ì'] = df['ì—°ë´‰'] > 4000

print("\nìƒˆ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame:")
print(df)
```

#### í–‰ ì„ íƒê³¼ í•„í„°ë§

```python
# ì¡°ê±´ì„ ì´ìš©í•œ í•„í„°ë§
high_salary = df[df['ì—°ë´‰'] > 4000]
print("ì—°ë´‰ 4000ë§Œì› ì´ìƒì¸ ì§ì›:")
print(high_salary)

# ì—¬ëŸ¬ ì¡°ê±´ ì¡°í•©
seoul_high_salary = df[(df['ë„ì‹œ'] == 'ì„œìš¸') & (df['ì—°ë´‰'] > 3000)]
print("\nì„œìš¸ì— ê±°ì£¼í•˜ê³  ì—°ë´‰ì´ 3000ë§Œì› ì´ìƒì¸ ì§ì›:")
print(seoul_high_salary)

# isin() ë©”ì„œë“œ ì‚¬ìš©
major_cities = df[df['ë„ì‹œ'].isin(['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬'])]
print("\nì£¼ìš” ë„ì‹œ ê±°ì£¼ì:")
print(major_cities)
```

#### ì •ë ¬

```python
# ë‹¨ì¼ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬
df_sorted_age = df.sort_values('ë‚˜ì´')
print("ë‚˜ì´ìˆœ ì •ë ¬:")
print(df_sorted_age)

# ì—¬ëŸ¬ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬
df_sorted_multi = df.sort_values(['ë„ì‹œ', 'ì—°ë´‰'], ascending=[True, False])
print("\në„ì‹œë³„, ì—°ë´‰ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬:")
print(df_sorted_multi)

# ì¸ë±ìŠ¤ë¡œ ì •ë ¬
df_sorted_index = df.sort_index()
print("\nì¸ë±ìŠ¤ ì •ë ¬:")
print(df_sorted_index)
```

---

## ì¤‘ê¸‰í¸

### ê³ ê¸‰ ì¸ë±ì‹±ê³¼ ì„ íƒ

#### .locì™€ .iloc í™œìš©

```python
# íŒë§¤ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì¤‘ê¸‰í¸ ë°ì´í„°ì…‹)
df_sales = pd.read_csv('datasets/sales_data.csv')
df_sales['date'] = pd.to_datetime(df_sales['date'])
df_sales = df_sales.set_index('date')

print("íŒë§¤ ë°ì´í„° (ê³ ê¸‰ ì¸ë±ì‹± ì˜ˆì œ):")
print(df_sales.head())

# .loc ì‚¬ìš© (ë¼ë²¨ ê¸°ë°˜)
print("\n.loc ì‚¬ìš© ì˜ˆì œ:")
print("íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„°:")
print(df_sales.loc['2024-01-01'])

print("\në‚ ì§œ ë²”ìœ„ì™€ íŠ¹ì • ì»¬ëŸ¼:")
print(df_sales.loc['2024-01-01':'2024-01-05', ['region', 'product', 'total_amount']])

# .iloc ì‚¬ìš© (ìœ„ì¹˜ ê¸°ë°˜)
print("\n.iloc ì‚¬ìš© ì˜ˆì œ:")
print("ì²˜ìŒ 5í–‰, ì²˜ìŒ 3ì»¬ëŸ¼:")
print(df_sales.iloc[:5, :3])

print("\níŠ¹ì • ìœ„ì¹˜ì˜ ê°’ë“¤:")
print(df_sales.iloc[[0, 2, 4], [1, 3, 5]])
```

#### ì¡°ê±´ë¶€ ì„ íƒê³¼ query ë©”ì„œë“œ

```python
# ë³µì¡í•œ ì¡°ê±´ í•„í„°ë§
condition = (df_sales['quantity'] > 10) & (df_sales['total_amount'] > 50000) & (df_sales['region'] == 'ì„œìš¸')
filtered_df = df_sales[condition]
print("ë³µì¡í•œ ì¡°ê±´ í•„í„°ë§ ê²°ê³¼ (ì„œìš¸, ìˆ˜ëŸ‰>10, ê¸ˆì•¡>50000):")
print(filtered_df.head())

# query ë©”ì„œë“œ ì‚¬ìš© (ë” ì½ê¸° ì‰¬ìš´ ë°©ë²•)
query_result = df_sales.query('quantity > 10 and total_amount > 50000 and region == "ì„œìš¸"')
print("\nquery ë©”ì„œë“œ ì‚¬ìš© ê²°ê³¼:")
print(query_result.head())

# ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ query
min_quantity = 15
min_amount = 100000
query_with_vars = df_sales.query('quantity > @min_quantity and total_amount > @min_amount')
print(f"\në³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ query (ìˆ˜ëŸ‰ > {min_quantity}, ê¸ˆì•¡ > {min_amount}):")
print(query_with_vars.head())
```

### ë°ì´í„° ì •ì œì™€ ë³€í™˜

#### ê²°ì¸¡ê°’ ì²˜ë¦¬

```python
# ê²°ì¸¡ê°’ì´ í¬í•¨ëœ íŒë§¤ ë°ì´í„° ì‚¬ìš©
df_missing = df_sales.copy()

print("ê²°ì¸¡ê°’ ì •ë³´:")
print(df_missing.isnull().sum())

# ê²°ì¸¡ê°’ í™•ì¸
print("\nê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰:")
print(df_missing[df_missing.isnull().any(axis=1)].head())

# ê²°ì¸¡ê°’ ì²˜ë¦¬ ë°©ë²•ë“¤
# 1. ê²°ì¸¡ê°’ ì œê±°
df_dropped = df_missing.dropna()
print(f"\nê²°ì¸¡ê°’ ì œê±° í›„ í¬ê¸°: {df_dropped.shape}")

# 2. íŠ¹ì • ì»¬ëŸ¼ì˜ ê²°ì¸¡ê°’ë§Œ ì œê±°
df_dropped_subset = df_missing.dropna(subset=['salesperson'])
print(f"salesperson ì»¬ëŸ¼ ê²°ì¸¡ê°’ë§Œ ì œê±° í›„ í¬ê¸°: {df_dropped_subset.shape}")

# 3. ê²°ì¸¡ê°’ ì±„ìš°ê¸°
df_filled = df_missing.fillna({
    'salesperson': 'ë¯¸ì§€ì •',  # ë¬¸ìì—´ë¡œ ì±„ìš°ê¸°
    'unit_price': df_missing['unit_price'].median(),  # ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    'customer_type': 'ì¼ë°˜'  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
})
print("\nê²°ì¸¡ê°’ì„ ì±„ìš´ í›„:")
print(df_filled.isnull().sum())

# 4. ì „ì§„/í›„ì§„ ì±„ìš°ê¸°
df_ffill = df_missing.fillna(method='ffill')  # ì•ì˜ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
df_bfill = df_missing.fillna(method='bfill')  # ë’¤ì˜ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
```

#### ë°ì´í„° íƒ€ì… ë³€í™˜

```python
# ë°ì´í„° íƒ€ì… í™•ì¸
print("í˜„ì¬ ë°ì´í„° íƒ€ì…:")
print(df_advanced.dtypes)

# ë°ì´í„° íƒ€ì… ë³€í™˜
df_converted = df_advanced.copy()
df_converted['C'] = df_converted['C'].astype('float64')
df_converted['D'] = df_converted['D'].astype('category')

print("\në³€í™˜ í›„ ë°ì´í„° íƒ€ì…:")
print(df_converted.dtypes)

# ì¹´í…Œê³ ë¦¬ ë°ì´í„°ì˜ ì¥ì 
print(f"\në©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ:")
print(f"ì›ë³¸ D ì»¬ëŸ¼: {df_advanced['D'].memory_usage(deep=True)} bytes")
print(f"ì¹´í…Œê³ ë¦¬ D ì»¬ëŸ¼: {df_converted['D'].memory_usage(deep=True)} bytes")
```

#### applyì™€ map í•¨ìˆ˜ í™œìš©

```python
# apply í•¨ìˆ˜ ì‚¬ìš©
def categorize_value(x):
    if x > 1:
        return 'High'
    elif x > 0:
        return 'Medium'
    else:
        return 'Low'

df_advanced['A_category'] = df_advanced['A'].apply(categorize_value)
print("apply í•¨ìˆ˜ ì ìš© ê²°ê³¼:")
print(df_advanced[['A', 'A_category']].head())

# lambda í•¨ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©
df_advanced['B_squared'] = df_advanced['B'].apply(lambda x: x**2)
print("\nlambda í•¨ìˆ˜ ì ìš© ê²°ê³¼:")
print(df_advanced[['B', 'B_squared']].head())

# DataFrame ì „ì²´ì— apply ì ìš©
numeric_cols = ['A', 'B', 'C']
df_normalized = df_advanced[numeric_cols].apply(lambda x: (x - x.mean()) / x.std())
print("\nì •ê·œí™”ëœ ë°ì´í„°:")
print(df_normalized.head())
```

### ê·¸ë£¹í™”ì™€ ì§‘ê³„

#### ê¸°ë³¸ ê·¸ë£¹í™”

```python
# ì‹¤ì œ íŒë§¤ ë°ì´í„° ì‚¬ìš©
print("íŒë§¤ ë°ì´í„°:")
print(df_sales.head(10))

# ê¸°ë³¸ ê·¸ë£¹í™”
region_group = df_sales.groupby('region')
print("\nì§€ì—­ë³„ í‰ê·  íŒë§¤ëŸ‰:")
print(region_group['quantity'].mean())

print("\nì§€ì—­ë³„ ì´ ë§¤ì¶œ:")
print(region_group['total_amount'].sum())

# ì œí’ˆë³„ ê·¸ë£¹í™”
product_group = df_sales.groupby('product')
print("\nì œí’ˆë³„ í‰ê·  ë‹¨ê°€:")
print(product_group['unit_price'].mean())
```

#### ë‹¤ì¤‘ ê·¸ë£¹í™”ì™€ ì§‘ê³„

```python
# ë‹¤ì¤‘ ê·¸ë£¹í™”
multi_group = df_sales.groupby(['region', 'product'])
print("ì§€ì—­ë³„, ì œí’ˆë³„ ì§‘ê³„:")
print(multi_group.agg({
    'quantity': ['sum', 'mean'],
    'total_amount': ['sum', 'max', 'min']
}))

# ì‚¬ìš©ì ì •ì˜ ì§‘ê³„ í•¨ìˆ˜
def amount_range(x):
    return x.max() - x.min()

custom_agg = df_sales.groupby('region').agg({
    'quantity': ['mean', 'std'],
    'total_amount': ['sum', 'count', amount_range]
})
print("\nì‚¬ìš©ì ì •ì˜ ì§‘ê³„:")
print(custom_agg)
```

#### transformê³¼ filter í™œìš©

```python
# transform: ê·¸ë£¹ë³„ ë³€í™˜
sales_data['ì§€ì—­ë³„_í‰ê· _íŒë§¤ëŸ‰'] = sales_data.groupby('ì§€ì—­')['íŒë§¤ëŸ‰'].transform('mean')
sales_data['í‰ê· ëŒ€ë¹„_ë¹„ìœ¨'] = sales_data['íŒë§¤ëŸ‰'] / sales_data['ì§€ì—­ë³„_í‰ê· _íŒë§¤ëŸ‰']

print("transform ê²°ê³¼:")
print(sales_data[['ì§€ì—­', 'íŒë§¤ëŸ‰', 'ì§€ì—­ë³„_í‰ê· _íŒë§¤ëŸ‰', 'í‰ê· ëŒ€ë¹„_ë¹„ìœ¨']].head())

# filter: ì¡°ê±´ì— ë§ëŠ” ê·¸ë£¹ë§Œ ì„ íƒ
high_sales_groups = sales_data.groupby('ì§€ì—­').filter(lambda x: x['ë§¤ì¶œ'].sum() > 50000)
print(f"\nê³ ë§¤ì¶œ ì§€ì—­ ë°ì´í„° ìˆ˜: {len(high_sales_groups)}")
print("ê³ ë§¤ì¶œ ì§€ì—­:")
print(high_sales_groups.groupby('ì§€ì—­')['ë§¤ì¶œ'].sum())
```

### ë°ì´í„° ë³‘í•©ê³¼ ê²°í•©

#### merge í•¨ìˆ˜ í™œìš©

```python
# ì‹¤ì œ ë°ì´í„°ì…‹ ì‚¬ìš©
customers = pd.read_csv('datasets/customers.csv')
orders = pd.read_csv('datasets/orders.csv')

print("ê³ ê° ë°ì´í„°:")
print(customers.head())
print("\nì£¼ë¬¸ ë°ì´í„°:")
print(orders.head())

# Inner Join (ê¸°ë³¸)
inner_merged = pd.merge(customers, orders, on='customer_id')
print("\nInner Join ê²°ê³¼:")
print(inner_merged)

# Left Join
left_merged = pd.merge(customers, orders, on='customer_id', how='left')
print("\nLeft Join ê²°ê³¼:")
print(left_merged)

# Right Join
right_merged = pd.merge(customers, orders, on='customer_id', how='right')
print("\nRight Join ê²°ê³¼:")
print(right_merged)

# Outer Join
outer_merged = pd.merge(customers, orders, on='customer_id', how='outer')
print("\nOuter Join ê²°ê³¼:")
print(outer_merged)
```

#### concat í•¨ìˆ˜ í™œìš©

```python
# concat ì˜ˆì œ ë°ì´í„°
df1 = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})

df2 = pd.DataFrame({
    'A': [7, 8, 9],
    'B': [10, 11, 12]
})

df3 = pd.DataFrame({
    'C': [13, 14, 15],
    'D': [16, 17, 18]
})

# ì„¸ë¡œ ì—°ê²°
vertical_concat = pd.concat([df1, df2], ignore_index=True)
print("ì„¸ë¡œ ì—°ê²°:")
print(vertical_concat)

# ê°€ë¡œ ì—°ê²°
horizontal_concat = pd.concat([df1, df3], axis=1)
print("\nê°€ë¡œ ì—°ê²°:")
print(horizontal_concat)

# í‚¤ë¥¼ ì‚¬ìš©í•œ ì—°ê²°
keyed_concat = pd.concat([df1, df2], keys=['first', 'second'])
print("\ní‚¤ë¥¼ ì‚¬ìš©í•œ ì—°ê²°:")
print(keyed_concat)
```

---

## ìµœì‹ ê¸°ëŠ¥í¸

### PyArrow ë°±ì—”ë“œ í™œìš©

PyArrowëŠ” pandasì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ìµœì‹  ë°±ì—”ë“œì…ë‹ˆë‹¤.

```python
# PyArrow ì„¤ì¹˜ í™•ì¸ ë° ì‚¬ìš©
try:
    import pyarrow as pa
    print(f"PyArrow ë²„ì „: {pa.__version__}")
    
    # PyArrow ë°±ì—”ë“œ Series ìƒì„±
    arrow_series = pd.Series([-1.545, 0.211, None], dtype="float32[pyarrow]")
    print("PyArrow ë°±ì—”ë“œ Series:")
    print(arrow_series)
    print(f"ë°ì´í„° íƒ€ì…: {arrow_series.dtype}")
    
    # ì„±ëŠ¥ í–¥ìƒëœ ì—°ì‚°
    print(f"\ní‰ê· : {arrow_series.mean()}")
    print(f"í•©ê³„: {arrow_series + arrow_series}")
    print(f"ë¹„êµ: {arrow_series > (arrow_series + 1)}")
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    print(f"\nê²°ì¸¡ê°’ ì œê±°: {arrow_series.dropna()}")
    print(f"ê²°ì¸¡ê°’ í™•ì¸: {arrow_series.isna()}")
    print(f"ê²°ì¸¡ê°’ ì±„ìš°ê¸°: {arrow_series.fillna(0)}")
    
    # ë¬¸ìì—´ PyArrow íƒ€ì…
    arrow_string_series = pd.Series(["a", "b", None], dtype=pd.ArrowDtype(pa.string()))
    print(f"\nPyArrow ë¬¸ìì—´ Series:")
    print(arrow_string_series)
    print(f"'a'ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸: {arrow_string_series.str.startswith('a')}")
    
except ImportError:
    print("PyArrowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pyarrowë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
```

### ê³ ê¸‰ ë¬¸ìì—´ ì²˜ë¦¬

```python
# ê³ ê° ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë¬¸ìì—´ ì²˜ë¦¬
text_data = customers[['name', 'email', 'phone', 'city']].head(10)

print("ë¬¸ìì—´ ë°ì´í„°:")
print(text_data)

# ë¬¸ìì—´ ë©”ì„œë“œ ì²´ì´ë‹
text_data['name_upper'] = text_data['name'].str.upper()
text_data['email_domain'] = text_data['email'].str.split('@').str[1]
text_data['phone_cleaned'] = text_data['phone'].str.replace('-', '')

print("\në¬¸ìì—´ ì²˜ë¦¬ ê²°ê³¼:")
print(text_data[['name', 'name_upper', 'email', 'email_domain', 'phone', 'phone_cleaned']])

# ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
text_data['area_code'] = text_data['phone'].str.extract(r'(\d{3})-\d{4}-\d{4}')
text_data['city_suffix'] = text_data['city'].str.extract(r'(\w+)ì‹œ')

print("\nì •ê·œí‘œí˜„ì‹ ì¶”ì¶œ ê²°ê³¼:")
print(text_data[['phone', 'area_code', 'city', 'city_suffix']])

# ë¬¸ìì—´ ì¡°ê±´ í•„í„°ë§
gmail_users = text_data[text_data['email'].str.contains('gmail')]
print("\nGmail ì‚¬ìš©ì:")
print(gmail_users[['name', 'email']])

# ë¬¸ìì—´ ê¸¸ì´ì™€ í†µê³„
text_data['name_length'] = text_data['name'].str.len()
print(f"\nì´ë¦„ ê¸¸ì´ í†µê³„:")
print(text_data['name_length'].describe())
```

### ì‹œê³„ì—´ ë°ì´í„° ê³ ê¸‰ ì²˜ë¦¬

```python
# ì£¼ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
stock_data = pd.read_csv('datasets/stock_data.csv')
stock_data['date'] = pd.to_datetime(stock_data['date'])

# íŠ¹ì • ì¢…ëª© ì„ íƒ (AAPL)
ts_data = stock_data[stock_data['symbol'] == 'AAPL'].copy()
ts_data.set_index('date', inplace=True)

print("ì‹œê³„ì—´ ë°ì´í„° (AAPL ì£¼ì‹):")
print(ts_data.head())

# ë‚ ì§œ/ì‹œê°„ ì†ì„± ì¶”ì¶œ
ts_data['year'] = ts_data.index.year
ts_data['month'] = ts_data.index.month
ts_data['day_of_week'] = ts_data.index.dayofweek
ts_data['quarter'] = ts_data.index.quarter

print("\në‚ ì§œ ì†ì„± ì¶”ì¶œ:")
print(ts_data[['close', 'year', 'month', 'day_of_week', 'quarter']].head())

# ë¦¬ìƒ˜í”Œë§
monthly_stock = ts_data['close'].resample('M').agg({
    'open': 'first',
    'high': 'max',
    'low': 'min',
    'close': 'last'
})
print("\nì›”ë³„ ì£¼ê°€ ì§‘ê³„:")
print(monthly_stock.head())

# ì´ë™ í‰ê· 
ts_data['close_ma_7'] = ts_data['close'].rolling(window=7).mean()
ts_data['close_ma_30'] = ts_data['close'].rolling(window=30).mean()

print("\nì´ë™ í‰ê· :")
print(ts_data[['close', 'close_ma_7', 'close_ma_30']].head(10))

# ì‹œì°¨ ë³€ìˆ˜ ìƒì„±
ts_data['close_lag_1'] = ts_data['close'].shift(1)
ts_data['close_lag_7'] = ts_data['close'].shift(7)
ts_data['close_diff'] = ts_data['close'].diff()
ts_data['returns'] = ts_data['close'].pct_change()

print("\nì‹œì°¨ ë³€ìˆ˜ì™€ ìˆ˜ìµë¥ :")
print(ts_data[['close', 'close_lag_1', 'close_diff', 'returns']].head(10))
```

### ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

#### ë©”ëª¨ë¦¬ ìµœì í™”

```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
def memory_usage(df):
    return df.memory_usage(deep=True).sum() / 1024**2  # MB ë‹¨ìœ„

# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
large_data = pd.read_csv('datasets/large_dataset.csv')

print(f"ì›ë³¸ ë°ì´í„° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage(large_data):.2f} MB")
print("ì›ë³¸ ë°ì´í„° íƒ€ì…:")
print(large_data.dtypes)
print(f"ë°ì´í„° í¬ê¸°: {large_data.shape}")

# ë©”ëª¨ë¦¬ ìµœì í™”
optimized_data = large_data.copy()
optimized_data['id'] = optimized_data['id'].astype('int32')  # int64 -> int32
optimized_data['category'] = optimized_data['category'].astype('category')  # object -> category
optimized_data['subcategory'] = optimized_data['subcategory'].astype('category')  # object -> category
optimized_data['value1'] = optimized_data['value1'].astype('float32')  # float64 -> float32
optimized_data['value2'] = optimized_data['value2'].astype('float32')  # float64 -> float32
optimized_data['value3'] = optimized_data['value3'].astype('int16')  # int64 -> int16

print(f"\nìµœì í™”ëœ ë°ì´í„° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage(optimized_data):.2f} MB")
print("ìµœì í™”ëœ ë°ì´í„° íƒ€ì…:")
print(optimized_data.dtypes)

memory_reduction = (1 - memory_usage(optimized_data) / memory_usage(large_data)) * 100
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ: {memory_reduction:.1f}%")
```

#### ë²¡í„°í™” ì—°ì‚° í™œìš©

```python
# ë²¡í„°í™” vs ë°˜ë³µë¬¸ ì„±ëŠ¥ ë¹„êµ
import time

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_data = pd.DataFrame({
    'A': np.random.randn(100000),
    'B': np.random.randn(100000)
})

# ë°˜ë³µë¬¸ ë°©ì‹ (ë¹„íš¨ìœ¨ì )
start_time = time.time()
result_loop = []
for i in range(len(test_data)):
    if test_data.iloc[i]['A'] > 0:
        result_loop.append(test_data.iloc[i]['B'] * 2)
    else:
        result_loop.append(test_data.iloc[i]['B'])
loop_time = time.time() - start_time

# ë²¡í„°í™” ë°©ì‹ (íš¨ìœ¨ì )
start_time = time.time()
result_vectorized = np.where(test_data['A'] > 0, test_data['B'] * 2, test_data['B'])
vectorized_time = time.time() - start_time

print(f"ë°˜ë³µë¬¸ ë°©ì‹ ì‹œê°„: {loop_time:.4f}ì´ˆ")
print(f"ë²¡í„°í™” ë°©ì‹ ì‹œê°„: {vectorized_time:.4f}ì´ˆ")
print(f"ì„±ëŠ¥ í–¥ìƒ: {loop_time/vectorized_time:.1f}ë°°")
```

#### evalê³¼ queryë¥¼ ì´ìš©í•œ ì„±ëŠ¥ í–¥ìƒ

```python
# evalê³¼ query ì„±ëŠ¥ ë¹„êµ
large_df = pd.DataFrame({
    'A': np.random.randn(100000),
    'B': np.random.randn(100000),
    'C': np.random.randn(100000),
    'D': np.random.randn(100000)
})

# ì¼ë°˜ì ì¸ ë°©ë²•
start_time = time.time()
result_normal = large_df[(large_df['A'] > 0) & (large_df['B'] < 0.5)]
normal_time = time.time() - start_time

# query ì‚¬ìš©
start_time = time.time()
result_query = large_df.query('A > 0 and B < 0.5')
query_time = time.time() - start_time

print(f"ì¼ë°˜ì ì¸ ë°©ë²• ì‹œê°„: {normal_time:.4f}ì´ˆ")
print(f"query ë°©ë²• ì‹œê°„: {query_time:.4f}ì´ˆ")

# eval ì‚¬ìš© (ë³µì¡í•œ ê³„ì‚°)
start_time = time.time()
result_eval = large_df.eval('E = A + B * C - D')
eval_time = time.time() - start_time

start_time = time.time()
large_df['E_normal'] = large_df['A'] + large_df['B'] * large_df['C'] - large_df['D']
normal_calc_time = time.time() - start_time

print(f"eval ê³„ì‚° ì‹œê°„: {eval_time:.4f}ì´ˆ")
print(f"ì¼ë°˜ ê³„ì‚° ì‹œê°„: {normal_calc_time:.4f}ì´ˆ")
```

## ğŸ¯ ì‹¤ì „ í”„ë¡œì íŠ¸: ì¢…í•© ë°ì´í„° ë¶„ì„

ë§ˆì§€ë§‰ìœ¼ë¡œ ë°°ìš´ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì‹¤ì „ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
# ì¢…í•© ì‹¤ìŠµ: ì „ììƒê±°ë˜ ë°ì´í„° ë¶„ì„
# ì‹¤ì œ ìƒì„±ëœ ë°ì´í„°ì…‹ë“¤ì„ í™œìš©

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
customers = pd.read_csv('datasets/customers.csv')
products = pd.read_csv('datasets/products.csv')
orders = pd.read_csv('datasets/orders.csv')

# ë°ì´í„° ì „ì²˜ë¦¬
orders['order_date'] = pd.to_datetime(orders['order_date'])
products['launch_date'] = pd.to_datetime(products['launch_date'])
customers['join_date'] = pd.to_datetime(customers['join_date'])

# ë°ì´í„° ë³‘í•©
full_data = orders.merge(customers, on='customer_id').merge(products, on='product_id')
full_data['total_amount'] = full_data['price'] * full_data['quantity']

print("ì¢…í•© ë°ì´í„° ìƒ˜í”Œ:")
print(full_data.head())
print(f"\nì „ì²´ ë°ì´í„° í¬ê¸°: {full_data.shape}")
print(f"ë¶„ì„ ê¸°ê°„: {full_data['order_date'].min()} ~ {full_data['order_date'].max()}")

# 1. ì›”ë³„ ë§¤ì¶œ ë¶„ì„
full_data['order_month'] = full_data['order_date'].dt.to_period('M')
monthly_sales = full_data.groupby('order_month')['total_amount'].agg(['sum', 'count', 'mean'])
monthly_sales.columns = ['ì´ë§¤ì¶œ', 'ì£¼ë¬¸ìˆ˜', 'í‰ê· ì£¼ë¬¸ê¸ˆì•¡']

print("\nì›”ë³„ ë§¤ì¶œ ë¶„ì„:")
print(monthly_sales.head())

# 2. ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼ ë¶„ì„
category_analysis = full_data.groupby('category').agg({
    'total_amount': ['sum', 'mean'],
    'quantity': 'sum',
    'customer_id': 'nunique'
}).round(2)

category_analysis.columns = ['ì´ë§¤ì¶œ', 'í‰ê· ì£¼ë¬¸ê¸ˆì•¡', 'ì´íŒë§¤ëŸ‰', 'ê³ ê°ìˆ˜']
category_analysis['ê³ ê°ë‹¹_í‰ê· ë§¤ì¶œ'] = (category_analysis['ì´ë§¤ì¶œ'] / category_analysis['ê³ ê°ìˆ˜']).round(2)

print("\nì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼ ë¶„ì„:")
print(category_analysis)

# 3. ê³ ê° ì„¸ê·¸ë©˜í…Œì´ì…˜
customer_metrics = full_data.groupby('customer_id').agg({
    'total_amount': ['sum', 'count', 'mean'],
    'order_date': ['min', 'max']
}).round(2)

customer_metrics.columns = ['ì´êµ¬ë§¤ê¸ˆì•¡', 'ì£¼ë¬¸íšŸìˆ˜', 'í‰ê· ì£¼ë¬¸ê¸ˆì•¡', 'ì²«êµ¬ë§¤ì¼', 'ë§ˆì§€ë§‰êµ¬ë§¤ì¼']
customer_metrics['êµ¬ë§¤ê¸°ê°„'] = (customer_metrics['ë§ˆì§€ë§‰êµ¬ë§¤ì¼'] - customer_metrics['ì²«êµ¬ë§¤ì¼']).dt.days

# RFM ë¶„ì„ì„ ìœ„í•œ ì§€í‘œ ê³„ì‚°
reference_date = full_data['order_date'].max()
customer_metrics['ìµœê·¼êµ¬ë§¤ì¼ìˆ˜'] = (reference_date - customer_metrics['ë§ˆì§€ë§‰êµ¬ë§¤ì¼']).dt.days

# ê³ ê° ë“±ê¸‰ ë¶„ë¥˜
def classify_customer(row):
    if row['ì´êµ¬ë§¤ê¸ˆì•¡'] > customer_metrics['ì´êµ¬ë§¤ê¸ˆì•¡'].quantile(0.8):
        return 'VIP'
    elif row['ì´êµ¬ë§¤ê¸ˆì•¡'] > customer_metrics['ì´êµ¬ë§¤ê¸ˆì•¡'].quantile(0.6):
        return 'ìš°ìˆ˜'
    elif row['ì´êµ¬ë§¤ê¸ˆì•¡'] > customer_metrics['ì´êµ¬ë§¤ê¸ˆì•¡'].quantile(0.4):
        return 'ì¼ë°˜'
    else:
        return 'ì‹ ê·œ'

customer_metrics['ê³ ê°ë“±ê¸‰'] = customer_metrics.apply(classify_customer, axis=1)

print("\nê³ ê° ë“±ê¸‰ë³„ ë¶„í¬:")
print(customer_metrics['ê³ ê°ë“±ê¸‰'].value_counts())

print("\nê³ ê° ë“±ê¸‰ë³„ í‰ê·  ì§€í‘œ:")
grade_analysis = customer_metrics.groupby('ê³ ê°ë“±ê¸‰').agg({
    'ì´êµ¬ë§¤ê¸ˆì•¡': 'mean',
    'ì£¼ë¬¸íšŸìˆ˜': 'mean',
    'í‰ê· ì£¼ë¬¸ê¸ˆì•¡': 'mean',
    'ìµœê·¼êµ¬ë§¤ì¼ìˆ˜': 'mean'
}).round(2)
print(grade_analysis)

# 4. ì§€ì—­ë³„ ë¶„ì„
region_analysis = full_data.groupby('city').agg({
    'total_amount': 'sum',
    'customer_id': 'nunique',
    'order_id': 'count'
}).round(2)

region_analysis.columns = ['ì´ë§¤ì¶œ', 'ê³ ê°ìˆ˜', 'ì£¼ë¬¸ìˆ˜']
region_analysis['ê³ ê°ë‹¹_ë§¤ì¶œ'] = (region_analysis['ì´ë§¤ì¶œ'] / region_analysis['ê³ ê°ìˆ˜']).round(2)
region_analysis['ê³ ê°ë‹¹_ì£¼ë¬¸ìˆ˜'] = (region_analysis['ì£¼ë¬¸ìˆ˜'] / region_analysis['ê³ ê°ìˆ˜']).round(2)

print("\nì§€ì—­ë³„ ë¶„ì„:")
print(region_analysis.sort_values('ì´ë§¤ì¶œ', ascending=False))

print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ì´ì œ ì—¬ëŸ¬ë¶„ì€ pandas ì¤‘ê³ ê¸‰ ì‚¬ìš©ìì…ë‹ˆë‹¤!")
```

## ğŸ“ ë§ˆë¬´ë¦¬ ë° ì¶”ê°€ í•™ìŠµ ê°€ì´ë“œ

### í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬

1. **ê¸°ë³¸í¸ì—ì„œ ë°°ìš´ ê²ƒë“¤:**
   - Seriesì™€ DataFrameì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ì¡°ì‘
   - ë°ì´í„° ì½ê¸°/ì“°ê¸°ì˜ ë‹¤ì–‘í•œ ë°©ë²•
   - ê¸°ë³¸ì ì¸ ë°ì´í„° ì„ íƒê³¼ í•„í„°ë§

2. **ì¤‘ê¸‰í¸ì—ì„œ ë°°ìš´ ê²ƒë“¤:**
   - .locì™€ .ilocì„ ì´ìš©í•œ ê³ ê¸‰ ì¸ë±ì‹±
   - ê²°ì¸¡ê°’ ì²˜ë¦¬ì™€ ë°ì´í„° íƒ€ì… ë³€í™˜
   - groupbyë¥¼ ì´ìš©í•œ ê°•ë ¥í•œ ì§‘ê³„ ê¸°ëŠ¥
   - mergeì™€ concatì„ ì´ìš©í•œ ë°ì´í„° ê²°í•©

3. **ìµœì‹ ê¸°ëŠ¥í¸ì—ì„œ ë°°ìš´ ê²ƒë“¤:**
   - PyArrow ë°±ì—”ë“œë¥¼ í†µí•œ ì„±ëŠ¥ í–¥ìƒ
   - ê³ ê¸‰ ë¬¸ìì—´ ì²˜ë¦¬ ê¸°ë²•
   - ì‹œê³„ì—´ ë°ì´í„°ì˜ ì „ë¬¸ì  ì²˜ë¦¬
   - ë©”ëª¨ë¦¬ ìµœì í™”ì™€ ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•

### ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ì¶”ì²œ

1. **ì‹œê°í™”**: plotlyì™€ pandas ì—°ë™ (ì•„ë˜ ì‹œê°í™” ì„¹ì…˜ ì°¸ê³ )
2. **ë¨¸ì‹ ëŸ¬ë‹**: scikit-learnê³¼ pandas ì—°ë™
3. **ëŒ€ìš©ëŸ‰ ë°ì´í„°**: Dask, Polars ë“± ëŒ€ì•ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬
4. **ì›¹ ê°œë°œ**: Streamlit, Dashë¥¼ ì´ìš©í•œ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

### ì‹¤ë¬´ íŒ

- í•­ìƒ ë°ì´í„°ì˜ í¬ê¸°ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”
- ë³µì¡í•œ ì—°ì‚°ì€ ì‘ì€ ìƒ˜í”Œë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”
- ì½”ë“œì˜ ê°€ë…ì„±ì„ ìœ„í•´ ë©”ì„œë“œ ì²´ì´ë‹ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”
- ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ê²½ìš° ë²¡í„°í™” ì—°ì‚°ì„ ìš°ì„  ê³ ë ¤í•˜ì„¸ìš”

---

## ğŸ“Š Plotlyë¥¼ í™œìš©í•œ ë°ì´í„° ì‹œê°í™”

pandasì™€ plotlyë¥¼ ì—°ë™í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œí•œ ì‹œê°í™”ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.

### Plotly ì„¤ì¹˜ ë° ê¸°ë³¸ ì„¤ì •

```python
# Plotly ì„¤ì¹˜ (í„°ë¯¸ë„ì—ì„œ)
# pip install plotly

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.offline as pyo

# Jupyter Notebookì—ì„œ ì‚¬ìš©í•  ê²½ìš°
pyo.init_notebook_mode(connected=True)
```

### ê¸°ë³¸ ì°¨íŠ¸ ìƒì„±

```python
# ì§ì› ë°ì´í„°ë¡œ ê¸°ë³¸ ì°¨íŠ¸ ë§Œë“¤ê¸°
df_employees = pd.read_csv('datasets/employees.csv')

# 1. ë§‰ëŒ€ ì°¨íŠ¸ - ë¶€ì„œë³„ ì§ì› ìˆ˜
dept_counts = df_employees['ë¶€ì„œ'].value_counts()

fig_bar = px.bar(
    x=dept_counts.index, 
    y=dept_counts.values,
    title='ë¶€ì„œë³„ ì§ì› ìˆ˜',
    labels={'x': 'ë¶€ì„œ', 'y': 'ì§ì› ìˆ˜'},
    color=dept_counts.values,
    color_continuous_scale='viridis'
)
fig_bar.show()

# 2. ì‚°ì ë„ - ë‚˜ì´ì™€ ì—°ë´‰ì˜ ê´€ê³„
fig_scatter = px.scatter(
    df_employees, 
    x='ë‚˜ì´', 
    y='ì—°ë´‰',
    color='ë¶€ì„œ',
    size='ì—°ë´‰',
    hover_data=['ì´ë¦„'],
    title='ë‚˜ì´ì™€ ì—°ë´‰ì˜ ê´€ê³„'
)
fig_scatter.show()

# 3. ë°•ìŠ¤ í”Œë¡¯ - ë¶€ì„œë³„ ì—°ë´‰ ë¶„í¬
fig_box = px.box(
    df_employees, 
    x='ë¶€ì„œ', 
    y='ì—°ë´‰',
    title='ë¶€ì„œë³„ ì—°ë´‰ ë¶„í¬',
    color='ë¶€ì„œ'
)
fig_box.show()
```

### íŒë§¤ ë°ì´í„° ì‹œê°í™”

```python
# íŒë§¤ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_sales = pd.read_csv('datasets/sales_data.csv')
df_sales['date'] = pd.to_datetime(df_sales['date'])

# 1. ì‹œê³„ì—´ ì°¨íŠ¸ - ì¼ë³„ ë§¤ì¶œ ì¶”ì´
daily_sales = df_sales.groupby('date')['total_amount'].sum().reset_index()

fig_line = px.line(
    daily_sales, 
    x='date', 
    y='total_amount',
    title='ì¼ë³„ ë§¤ì¶œ ì¶”ì´',
    labels={'date': 'ë‚ ì§œ', 'total_amount': 'ë§¤ì¶œì•¡'}
)
fig_line.update_traces(line_color='#1f77b4', line_width=2)
fig_line.show()

# 2. íŒŒì´ ì°¨íŠ¸ - ì§€ì—­ë³„ ë§¤ì¶œ ë¹„ì¤‘
region_sales = df_sales.groupby('region')['total_amount'].sum()

fig_pie = px.pie(
    values=region_sales.values,
    names=region_sales.index,
    title='ì§€ì—­ë³„ ë§¤ì¶œ ë¹„ì¤‘'
)
fig_pie.show()

# 3. íˆíŠ¸ë§µ - ì§€ì—­ë³„, ì œí’ˆë³„ ë§¤ì¶œ
pivot_data = df_sales.pivot_table(
    values='total_amount', 
    index='region', 
    columns='product', 
    aggfunc='sum'
).fillna(0)

fig_heatmap = px.imshow(
    pivot_data.values,
    x=pivot_data.columns,
    y=pivot_data.index,
    title='ì§€ì—­ë³„, ì œí’ˆë³„ ë§¤ì¶œ íˆíŠ¸ë§µ',
    color_continuous_scale='RdYlBu_r'
)
fig_heatmap.show()
```

### ì£¼ì‹ ë°ì´í„° ì‹œê°í™”

```python
# ì£¼ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_stocks = pd.read_csv('datasets/stock_data.csv')
df_stocks['date'] = pd.to_datetime(df_stocks['date'])

# 1. ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ - AAPL ì£¼ê°€
aapl_data = df_stocks[df_stocks['symbol'] == 'AAPL'].head(100)

fig_candlestick = go.Figure(data=go.Candlestick(
    x=aapl_data['date'],
    open=aapl_data['open'],
    high=aapl_data['high'],
    low=aapl_data['low'],
    close=aapl_data['close']
))

fig_candlestick.update_layout(
    title='AAPL ì£¼ê°€ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸',
    xaxis_title='ë‚ ì§œ',
    yaxis_title='ì£¼ê°€ ($)'
)
fig_candlestick.show()

# 2. ë‹¤ì¤‘ ì„  ì°¨íŠ¸ - ì—¬ëŸ¬ ì¢…ëª© ë¹„êµ
fig_multi = px.line(
    df_stocks, 
    x='date', 
    y='close', 
    color='symbol',
    title='ì£¼ìš” ì¢…ëª© ì£¼ê°€ ë¹„êµ'
)
fig_multi.show()

# 3. ì„œë¸Œí”Œë¡¯ - ì£¼ê°€ì™€ ê±°ë˜ëŸ‰
fig_subplots = make_subplots(
    rows=2, cols=1,
    subplot_titles=('ì£¼ê°€', 'ê±°ë˜ëŸ‰'),
    vertical_spacing=0.1
)

# ì£¼ê°€ ì°¨íŠ¸
for symbol in df_stocks['symbol'].unique():
    symbol_data = df_stocks[df_stocks['symbol'] == symbol]
    fig_subplots.add_trace(
        go.Scatter(x=symbol_data['date'], y=symbol_data['close'], 
                  name=f'{symbol} ì£¼ê°€', line=dict(width=2)),
        row=1, col=1
    )

# ê±°ë˜ëŸ‰ ì°¨íŠ¸
for symbol in df_stocks['symbol'].unique():
    symbol_data = df_stocks[df_stocks['symbol'] == symbol]
    fig_subplots.add_trace(
        go.Scatter(x=symbol_data['date'], y=symbol_data['volume'], 
                  name=f'{symbol} ê±°ë˜ëŸ‰', line=dict(width=1)),
        row=2, col=1
    )

fig_subplots.update_layout(height=600, title_text="ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ë¶„ì„")
fig_subplots.show()
```

### ì„¼ì„œ ë°ì´í„° ì‹œê°í™”

```python
# ì„¼ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_sensors = pd.read_csv('datasets/sensor_data.csv')
df_sensors['timestamp'] = pd.to_datetime(df_sensors['timestamp'])

# 1. ì‹œê³„ì—´ ë‹¤ì¤‘ ë³€ìˆ˜ ì°¨íŠ¸
fig_sensors = make_subplots(
    rows=3, cols=1,
    subplot_titles=('ì˜¨ë„', 'ìŠµë„', 'ê¸°ì••'),
    vertical_spacing=0.08
)

# ì˜¨ë„
fig_sensors.add_trace(
    go.Scatter(x=df_sensors['timestamp'][:1000], y=df_sensors['temperature'][:1000],
              name='ì˜¨ë„', line=dict(color='red')),
    row=1, col=1
)

# ìŠµë„
fig_sensors.add_trace(
    go.Scatter(x=df_sensors['timestamp'][:1000], y=df_sensors['humidity'][:1000],
              name='ìŠµë„', line=dict(color='blue')),
    row=2, col=1
)

# ê¸°ì••
fig_sensors.add_trace(
    go.Scatter(x=df_sensors['timestamp'][:1000], y=df_sensors['pressure'][:1000],
              name='ê¸°ì••', line=dict(color='green')),
    row=3, col=1
)

fig_sensors.update_layout(height=800, title_text="ì„¼ì„œ ë°ì´í„° ëª¨ë‹ˆí„°ë§")
fig_sensors.show()

# 2. 3D ì‚°ì ë„ - ì˜¨ë„, ìŠµë„, ê¸°ì•• ê´€ê³„
fig_3d = px.scatter_3d(
    df_sensors.sample(1000), 
    x='temperature', 
    y='humidity', 
    z='pressure',
    color='location',
    title='ì˜¨ë„-ìŠµë„-ê¸°ì•• 3D ê´€ê³„ë„'
)
fig_3d.show()
```

### ê³ ê° ë¶„ì„ ì‹œê°í™”

```python
# ê³ ê° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_customers = pd.read_csv('datasets/customers.csv')

# 1. íˆìŠ¤í† ê·¸ë¨ - ë‚˜ì´ ë¶„í¬
fig_hist = px.histogram(
    df_customers, 
    x='age', 
    nbins=20,
    title='ê³ ê° ë‚˜ì´ ë¶„í¬',
    color_discrete_sequence=['skyblue']
)
fig_hist.show()

# 2. ë°”ì´ì˜¬ë¦° í”Œë¡¯ - ë©¤ë²„ì‹­ ë ˆë²¨ë³„ ì´ êµ¬ë§¤ì•¡
fig_violin = px.violin(
    df_customers, 
    x='membership_level', 
    y='total_spent',
    title='ë©¤ë²„ì‹­ ë ˆë²¨ë³„ ì´ êµ¬ë§¤ì•¡ ë¶„í¬',
    box=True
)
fig_violin.show()

# 3. ì„ ë²„ìŠ¤íŠ¸ ì°¨íŠ¸ - ë„ì‹œë³„, ì„±ë³„, ë©¤ë²„ì‹­ ë ˆë²¨ ë¶„í¬
fig_sunburst = px.sunburst(
    df_customers, 
    path=['city', 'gender', 'membership_level'],
    title='ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬'
)
fig_sunburst.show()
```

### ëŒ€ì‹œë³´ë“œ ìŠ¤íƒ€ì¼ ì¢…í•© ì°¨íŠ¸

```python
# ì¢…í•© ëŒ€ì‹œë³´ë“œ ë§Œë“¤ê¸°
fig_dashboard = make_subplots(
    rows=2, cols=2,
    subplot_titles=('ì›”ë³„ ë§¤ì¶œ', 'ì§€ì—­ë³„ ë§¤ì¶œ', 'ì œí’ˆë³„ íŒë§¤ëŸ‰', 'ê³ ê° ì—°ë ¹ ë¶„í¬'),
    specs=[[{"type": "scatter"}, {"type": "bar"}],
           [{"type": "bar"}, {"type": "histogram"}]]
)

# ì›”ë³„ ë§¤ì¶œ
monthly_sales = df_sales.groupby(df_sales['date'].dt.to_period('M'))['total_amount'].sum()
fig_dashboard.add_trace(
    go.Scatter(x=monthly_sales.index.astype(str), y=monthly_sales.values,
              mode='lines+markers', name='ì›”ë³„ ë§¤ì¶œ'),
    row=1, col=1
)

# ì§€ì—­ë³„ ë§¤ì¶œ
region_sales = df_sales.groupby('region')['total_amount'].sum()
fig_dashboard.add_trace(
    go.Bar(x=region_sales.index, y=region_sales.values, name='ì§€ì—­ë³„ ë§¤ì¶œ'),
    row=1, col=2
)

# ì œí’ˆë³„ íŒë§¤ëŸ‰
product_qty = df_sales.groupby('product')['quantity'].sum()
fig_dashboard.add_trace(
    go.Bar(x=product_qty.index, y=product_qty.values, name='ì œí’ˆë³„ íŒë§¤ëŸ‰'),
    row=2, col=1
)

# ê³ ê° ì—°ë ¹ ë¶„í¬
fig_dashboard.add_trace(
    go.Histogram(x=df_customers['age'], name='ê³ ê° ì—°ë ¹'),
    row=2, col=2
)

fig_dashboard.update_layout(
    height=800, 
    title_text="ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ",
    showlegend=False
)
fig_dashboard.show()
```

### ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥ í™œìš©

```python
# ë“œë¡­ë‹¤ìš´ ë©”ë‰´ê°€ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
fig_interactive = go.Figure()

# ê° ì§€ì—­ë³„ ë°ì´í„° ì¶”ê°€
for region in df_sales['region'].unique():
    region_data = df_sales[df_sales['region'] == region]
    daily_data = region_data.groupby('date')['total_amount'].sum()
    
    fig_interactive.add_trace(
        go.Scatter(
            x=daily_data.index,
            y=daily_data.values,
            name=region,
            visible=True if region == 'ì„œìš¸' else False
        )
    )

# ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ìƒì„±
dropdown_buttons = []
for i, region in enumerate(df_sales['region'].unique()):
    visibility = [False] * len(df_sales['region'].unique())
    visibility[i] = True
    
    dropdown_buttons.append(
        dict(
            label=region,
            method="update",
            args=[{"visible": visibility}]
        )
    )

fig_interactive.update_layout(
    title="ì§€ì—­ë³„ ë§¤ì¶œ ì¶”ì´ (ì¸í„°ë™í‹°ë¸Œ)",
    updatemenus=[
        dict(
            buttons=dropdown_buttons,
            direction="down",
            showactive=True,
            x=0.1,
            y=1.15
        )
    ]
)
fig_interactive.show()
```

### Plotly ì°¨íŠ¸ ì €ì¥í•˜ê¸°

```python
# ì°¨íŠ¸ë¥¼ HTML íŒŒì¼ë¡œ ì €ì¥
fig_bar.write_html("ë¶€ì„œë³„_ì§ì›ìˆ˜.html")

# ì°¨íŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥ (kaleido íŒ¨í‚¤ì§€ í•„ìš”)
# pip install kaleido
try:
    fig_scatter.write_image("ë‚˜ì´_ì—°ë´‰_ê´€ê³„.png", width=800, height=600)
    fig_pie.write_image("ì§€ì—­ë³„_ë§¤ì¶œë¹„ì¤‘.pdf", width=800, height=600)
    print("ì°¨íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
except Exception as e:
    print(f"ì´ë¯¸ì§€ ì €ì¥ì„ ìœ„í•´ kaleido íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install kaleido")
    print(f"ì˜¤ë¥˜: {e}")
```

### ğŸ“Š ì‹œê°í™” íŒ

1. **ìƒ‰ìƒ ì„ íƒ**: `color_discrete_sequence`ë‚˜ `color_continuous_scale`ë¡œ ë¸Œëœë“œ ì»¬ëŸ¬ ì ìš©
2. **ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥**: ì¤Œ, íŒ¬, í˜¸ë²„ ë“± ê¸°ë³¸ ì œê³µë˜ëŠ” ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥ í™œìš©
3. **ë°˜ì‘í˜• ë””ìì¸**: `fig.update_layout(autosize=True)`ë¡œ ë°˜ì‘í˜• ì°¨íŠ¸ ìƒì„±
4. **ì• ë‹ˆë©”ì´ì…˜**: `animation_frame` ë§¤ê°œë³€ìˆ˜ë¡œ ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ì‹œê°í™”
5. **í…Œë§ˆ ì ìš©**: `template` ë§¤ê°œë³€ìˆ˜ë¡œ ì¼ê´€ëœ ë””ìì¸ ì ìš©

ì´ì œ ì—¬ëŸ¬ë¶„ì€ pandasì™€ plotlyë¥¼ ì—°ë™í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œí•˜ê³  ì•„ë¦„ë‹¤ìš´ ì‹œê°í™”ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ“ˆâœ¨

---

ì´ì œ ì—¬ëŸ¬ë¶„ì€ pandasë¥¼ í™œìš©í•˜ì—¬ ì‹¤ë¬´ì—ì„œ ë§ˆì£¼ì¹˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ë°ì´í„° ë¶„ì„ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³„ì†í•´ì„œ ì‹¤ì œ ë°ì´í„°ë¡œ ì—°ìŠµí•˜ë©° ì‹¤ë ¥ì„ í–¥ìƒì‹œì¼œ ë‚˜ê°€ì„¸ìš”! ğŸš€
