{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🐍 파이썬 텍스트 분석: 고전적 벡터화 기법 실습 과제\n",
    "\n",
    "이 노트북은 '고전적 벡터화 기법 마스터하기' 튜토리얼의 연습 문제와 최종 실습 프로젝트를 포함합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kiwipiepy scikit-learn pandas gensim plotly_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Kiwi 형태소 분석기 초기화\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag-of-Words (BoW)와 DTM: 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습용 데이터**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    '배우의 연기력이 정말 대단한 영화였어요.',\n",
    "    '스토리가 너무 예측 가능해서 연기력이 아까웠다.',\n",
    "    '감독의 연출과 배우의 연기가 조화로웠던 영화.',\n",
    "    '와 이 영화 진짜 대박이야! 배우들 연기 미쳤고 스토리도 완전 몰입됨',\n",
    "    '음... 좀 아쉽네요. 감독이 뭘 말하고 싶었는지 모르겠어요',\n",
    "    '연기는 괜찮았는데 결말이 너무 뻔해서 실망했습니다',\n",
    "    '헐 이거 완전 꿀잼ㅋㅋ 예상 못한 반전에 소름돋았어',\n",
    "    '감독님... 제발 좀 더 신경써서 찍으시길... 연출이 엉망이에요',\n",
    "    '주연배우 연기 진짜 자연스럽더라! 몰입도 최고였음',\n",
    "    '스토리가 조금 복잡하긴 했지만 나름 볼만했어요',\n",
    "    '이런 영화를 왜 만들었는지 이해가 안 가네... 시간 아까움',\n",
    "    '배우들 케미 완전 좋았고 연출도 깔끔했음. 추천!',\n",
    "    '예측할 수 없는 전개로 끝까지 출긴장감 넘쳤습니다',\n",
    "    '연기력은 인정하지만 스토리가 너무 뻔해서... 그냥 그래요',\n",
    "    '감독의 의도는 좋았으나 표현 방식이 아쉬웠네요',\n",
    "    'ㅋㅋㅋ 이거 뭐야 완전 재밌잖아? 배우들 연기 ㄹㅇ 대단함',\n",
    "    '조용한 영화인데 배우들 연기가 워낙 좋아서 지루하지 않았어요',\n",
    "    '액션은 별로였지만 인간관계 드라마가 탄탄해서 만족',\n",
    "    '아 진짜... 왜 이렇게 만들었을까? 감독 뭐하는 거야',\n",
    "    '처음엔 지루했는데 중반부터 완전 몰입! 연출 센스 있네',\n",
    "    '배우들 연기는 좋았지만 전체적으로 밋밋한 느낌이에요',\n",
    "    '와... 이런 스토리는 처음 봐! 정말 신선하고 감동적이었어',\n",
    "    '연출과 연기 모두 완벽했습니다. 올해 최고의 작품 중 하나!',\n",
    "    '뭔가 아쉬운 부분들이 있지만 그래도 볼만한 영화였어요'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**문제 1: 토크나이저를 수정하여 일반 명사(`NNG`)만 추출하고 DTM을 생성하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 1번 풀이 공간\n",
    "\n",
    "# 1. NNG만 추출하는 토크나이저 정의\n",
    "# 2. CountVectorizer 생성 및 DTM 구축\n",
    "# 3. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**문제 2: `ngram_range=(1, 2)`를 사용하여 DTM을 만들고 어휘 사전을 확인하세요.**\n",
    "\n",
    "* **`ngram_range=(1, 2)`의 의미:** 단어를 1개씩(unigram) 그리고 연속된 2개씩(bigram) 묶어서 토큰으로 사용하겠다는 의미입니다. 예를 들어 '배우 연기'가 토큰화되면, '배우', '연기' (unigrams) 뿐만 아니라 '배우 연기' (bigram)도 하나의 피처로 간주합니다. 이를 통해 단어의 순서 정보를 일부 보존할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 2번 풀이 공간\n",
    "\n",
    "# 튜토리얼의 기본 토크나이저를 다시 사용합니다.\n",
    "\n",
    "# 1. ngram_range를 적용하여 CountVectorizer 생성\n",
    "# 2. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF: 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**문제 1: 학습된 `TfidfVectorizer`의 `idf_` 속성을 확인하고, IDF 값이 가장 높은 단어와 낮은 단어를 찾아 그 이유를 설명하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 1번 풀이 공간\n",
    "\n",
    "# 튜토리얼 예제 코드 재사용\n",
    "\n",
    "# 1. 단어와 IDF 값을 묶어서 DataFrame 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**문제 2: `max_df=0.8`, `min_df=2` 파라미터를 추가하여 TF-IDF 행렬을 다시 만들고 어휘 사전의 변화를 확인하세요.**\n",
    "\n",
    "* `max_df=0.8`: 단어가 전체 문서의 80%를 초과하여 나타나면 어휘 사전에서 제외합니다. 너무 흔한 단어를 제거하는 역할을 합니다. (0~1 사이의 float 값은 비율, 정수 값은 문서 수를 의미합니다.)\n",
    "* `min_df=2`: 단어가 최소 2개 이상의 문서에 나타나야만 어휘 사전에 포함시킵니다. 너무 희귀한 단어나 오탈자를 제거하는 효과가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 2번 풀이 공간\n",
    "\n",
    "# 1. max_df, min_df 파라미터를 적용하여 TfidfVectorizer 생성\n",
    "# 2. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 & 4. Word2Vec & FastText: 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실습용 데이터**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사, 동사, 형용사만 추출\n",
    "tokenized_corpus = [\n",
    "    [token.form for token in kiwi.tokenize(doc) if token.tag in ['NNG', 'NNP', 'VV', 'VA']]\n",
    "    for doc in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec 문제 1: `vector_size=200`, `window=5`로 변경하여 모델을 만들고 '영화'와 유사한 단어를 찾으세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 1번 풀이 공간 (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec 문제 2: '연기' vs '연출', '연기' vs '스토리' 유사도를 비교 분석하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 2번 풀이 공간 (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FastText 문제 1: OOV 단어 '시나리오'의 유사 단어를 찾아보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습 문제 1번 풀이 공간 (FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💼 실습 프로젝트: 영화 리뷰 감성 분석 및 핵심어 시각화\n",
    "\n",
    "**데이터 다운로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naver Sentiment Movie Corpus 다운로드\n",
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt -O ratings_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 데이터 로드 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 (탭으로 구분되어 있음)\n",
    "df = pd.read_csv('ratings_train.txt', sep='\\t')\n",
    "\n",
    "# 결측치 제거\n",
    "\n",
    "\n",
    "\n",
    "# 분석을 위해 데이터 1000개 샘플링 (실제 프로젝트에서는 전체 데이터 사용)\n",
    "\n",
    "\n",
    "\n",
    "# kiwipiepy 토크나이저 (명사, 동사, 형용사, 부사 추출)\n",
    "def nsmc_tokenizer(text):\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    return [token.form for token in tokens if token.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG']]\n",
    "\n",
    "# X (리뷰), y (라벨) 분리\n",
    "X = # 작성\n",
    "y = # 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. TF-IDF 기반 모델링 및 핵심어 추출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 추가 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. BM25 기반 모델링 및 관련도 추출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# BM25를 위한 문서 토큰화\n",
    "\n",
    "# BM25 객체 생성\n",
    "\n",
    "# 테스트 질의 정의\n",
    "\n",
    "# BM25 기반 문서 검색 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. (심화) Word2Vec 임베딩 학습 및 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플 데이터 토큰화\n",
    "tokenized_nsmc = [nsmc_tokenizer(doc) for doc in X]\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "w2v_nsmc_model = Word2Vec(sentences=tokenized_nsmc, vector_size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "\n",
    "# 주요 단어 및 유사어 리스트\n",
    "\n",
    "\n",
    "# 중복을 반드시 제거하세요.\n",
    "vocab_to_show = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA로 2차원 축소 기법입니다. 머신러닝 비지도 학습의 한 기법으로 아직 공부하지 않은 영역이라, 코드 스니펫(조각)을 드리니, 아래 'vocab_to_show' 변수를 위 셀에서 만들어서 이 셀을 실행하세요.\n",
    "\n",
    "# 시각화를 위한 단어 벡터 추출\n",
    "word_vectors = np.array([w2v_nsmc_model.wv[word] for word in vocab_to_show])\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(word_vectors)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_result, columns=['x', 'y'])\n",
    "pca_df['word'] = vocab_to_show\n",
    "\n",
    "# Plotly Express로 시각화\n",
    "fig = px.scatter(pca_df, x='x', y='y', text='word', title='Word2Vec 임베딩 시각화 (PCA)')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
